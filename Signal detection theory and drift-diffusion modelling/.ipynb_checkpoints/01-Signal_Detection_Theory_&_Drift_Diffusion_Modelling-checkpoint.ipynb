{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bPdg2raoWEPt"
   },
   "source": [
    "## CCNSSS 2018 Module 2: Perceptual inference and motor control\n",
    "\n",
    "#  Tutorial 1 : Signal Detection Theory & Drift Diffusion Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJJeTr_lYty5"
   },
   "source": [
    "*Please execute the cells below to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:24:59.286847Z",
     "start_time": "2018-06-12T11:24:57.814618Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VIM0W3fjYty5"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "\n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows to call the function 'hide_toggle' that shows/hides solutions for each exercise\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Show/hide Solution below'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' '\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0bAuoi_2WMs0"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "In this notebook we'll look at *Signal Detection Theory (SDT)* and implement a *Drift diffusion model (DDM)* to simulate some data.\n",
    "\n",
    "SDT:\n",
    "\n",
    "- use random distributions in Python\n",
    "- visualize data in Python\n",
    "- practice $d'$ sensitivity analysis on mock data\n",
    "- practice Receiver Operating Characteristic (ROC) analysis on mock data\n",
    "\n",
    "DDM:\n",
    "\n",
    "\n",
    "- What do reaction time distributions look like?\n",
    "- How do distributions for correct and incorrect trials differ?\n",
    "- How can these properties be understood in terms of the Drift Diffusion Model?\n",
    "- simulate the Drift Diffusion Model\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmSPDGW4Yty8"
   },
   "source": [
    "## Background (SDT)\n",
    "\n",
    "Signal detection theory (SDT) is used when we want to measure the way we make decisions under conditions of uncertainty (for example: how well would we detect the presence of a car in front of us, while driving under foggy conditions). \n",
    "\n",
    "SDT assumes that the decision maker is not a passive receiver of information, but an active decision-maker who makes difficult perceptual judgments under conditions of uncertainty. \n",
    "\n",
    "In our example, in foggy circumstances, we are forced to decide whether there is an object in front of us based solely upon visual stimulus, which is impaired by the fog. The density of the fog makes detecting a car in front of us more difficult (and is a function of your distance from the car and the fog density). \n",
    "\n",
    "Signal Detection Theory can be applied to a data set where stimuli were either present or absent (e.g. stim = car, or no_car), and the observer categorized each trial as detecting the stimulus as being present or absent (detect=car, or no_car). These tasks are also known as 2-Alternative Forced Choice tasks (2-AFC for short). In such tasks, the trials can be sorted into one of four categories:\n",
    "\n",
    "![](./figures/2AFC_table.png)\n",
    "\n",
    "Signal detection theory is a means to quantify the ability to differentiate between valid information (signal) and noise. Multiple measures can be extracted using SDT: \n",
    "\n",
    "* the $d'$ (pronoumced dee-prime): is a measure of sensitivity (how hard/easy is it to perceive a stimulus under uncertainty). \n",
    "            *How easy/hard is it to see a car under foggy conditions for each participant?*\n",
    "* the bias (sometimes called 'threshold') '$c$': is a measure of bias in discriminating signal from noise. \n",
    "            *Does each participant have a tendency to overestimate or underestimate a car being present?*\n",
    "* the Receiver Operating Characteristic curve (ROC): enables to illustrate the ability of a participant to discriminate between signal and noise as the threshold and/or uncertainty is varied. \n",
    "            *How does the participant ability to detect a car changes as a function of fog density*\n",
    "            or\n",
    "            *How does the participant ability to detect a car changes as a function of their threshold/bias*\n",
    "\n",
    "___\n",
    "\n",
    "Graphically, you may think of the signal and the noise are overlapping distributions (signal: red distribution, noise: blue distribution). The threshold (or bias) is a boundary that separates the signal from the noise and defines whether the participant responds 'present' or 'not present'. \n",
    "\n",
    "When the threshold is set very low, noise might inadvertently be classified as signal (i.e. many false positives (FP)). \n",
    "\n",
    "Conversely, when the threshold is set very high, signal might be classified as noise (many false negatives, FN)).\n",
    "\n",
    "![](./figures/roc.png)\n",
    "\n",
    "ps: SDT measures can also be used to study any kind of binary classifiers (say: how good is a routine test at detecting cancer). In this case, having a conservative bias (low threshold) would result in more false positive, but depending on the application it could be a good thing. It is better to have a false alarm leading to a follow-up in a clinic, rather than missing a true cancer being present.\n",
    "\n",
    "For more info: [https://en.wikipedia.org/wiki/Receiver_operating_characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vJS7ZB0dYMUZ"
   },
   "source": [
    "**EXERCISE 1**\n",
    "\n",
    "Using normal distributions, we will create a sysnthetic dataset of noise and signal distributions.\n",
    "\n",
    "Let the distributions follow the following form: \n",
    "\\begin{align*} \\mathcal{N}_{signal}\\left(\\mu,\\sigma\\right),\\qquad \\mu=15, \\sigma=3 \\end{align*}\n",
    "\\begin{align*} \\mathcal{N}_{noise}\\left(\\mu,\\sigma\\right),\\qquad \\mu=10, \\sigma=2.5 \\end{align*}\n",
    "\n",
    "**Suggestions**\n",
    "* For reproducibility, set the seed to 0\n",
    "* Draw 10,000 samples from a normal distribution with mean '$\\mu$' and standard deviation '$\\sigma$' for the signal distribution (hint: you may use numpy.random functions)\n",
    "* Now do the same but for the noise distribution\n",
    "* Plot the histograms of the signal and noise distributions on the same plot(hint: you may use matplotlib.hist function). You may play around with the arguments 'bins', 'density', 'color', 'alpha', 'legend' until you can reproduce the expected figure below.\n",
    "* Plot on top of the histogram the true probability density function that generated the data (i.e. the normal distributions with mean '$\\mu$' and standard deviation '$\\sigma$'). Hint: you may import scipy.stats.\n",
    "* Add a vertical line representing the decision criterion (a.k.a. 'threshold') used to separate data as being either noise or signal (hint: you may use matplotlib.axvline). Use 12.3 as a decision criteria for now.\n",
    "* Show the legend in the top right corner of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_5034898911229775043() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_5034898911229775043()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:01.015428Z",
     "start_time": "2018-06-12T11:24:59.289172Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### SOLUTION\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "mu1, s1 = 10, 2.5\n",
    "mu2, s2 = 15, 3\n",
    "n_samples = 10000\n",
    "\n",
    "y1 = np.random.normal(mu1, s1, size=n_samples) \n",
    "y2 = np.random.normal(mu2, s2, size=n_samples) \n",
    "\n",
    "plt.hist(y1, bins=25, density = True, \n",
    "                          histtype='stepfilled', color='r',\n",
    "                          alpha=0.4, linewidth=0, label='noise')\n",
    "\n",
    "plt.plot(np.arange(0,30,0.1), sp.stats.norm.pdf(np.arange(0,30,0.1), mu1, s1), color = 'r', linewidth=2)\n",
    "\n",
    "plt.hist(y2, bins=25, density = True, \n",
    "                          histtype='stepfilled', color = 'b',\n",
    "                          alpha=0.4, linewidth=0, label='signal')\n",
    "\n",
    "plt.plot(np.arange(0,30,0.1), sp.stats.norm.pdf(np.arange(0,30,0.1), mu2, s2), color = 'b', linewidth=2)\n",
    "\n",
    "plt.axvline(12.5, color='black', linewidth=1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected output***\n",
    "\n",
    "![](./figures/expected_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T15:12:19.626458Z",
     "start_time": "2018-06-07T15:12:19.619240Z"
    }
   },
   "source": [
    "***EXERCISE 2: Sensitivity ($d'$) and specificity analysis.***\n",
    "\n",
    "$d'$ is a dimensionless statistic. A higher $d'$ indicates that the signal can be more readily detected.\n",
    "\n",
    "The sensitivity index or d' provides the separation between the means of the signal and the noise distributions, compared against the standard deviation of the signal or noise distribution. For normally distributed signal ($s$) and noise ($n$), with mean and standard deviations $\\mu _{S}$ and $\\sigma _{S}$ , and $\\mu _{N}$ $\\sigma _{N}$, respectively, $d'$ is defined as:\n",
    "\n",
    "\\begin{align*} d'=\\frac {\\mu _{S}-\\mu _{N}}{\\sqrt {{\\frac {1}{2}}\\left(\\sigma _{S}^{2}+\\sigma _{N}^{2}\\right)}} \\end{align*}\n",
    "\n",
    "![](./figures/deeprime.png)\n",
    "\n",
    "An estimate of $d'$ can be also found from measurements of the hit rate and false-alarm rate. It is calculated as:\n",
    "\n",
    "\\begin{align*} d' = Z(hit rate) − Z(false alarm rate) \\end{align*}\n",
    "\n",
    "where function $Z(p)$, $p \\in \\left[0,1\\right]$, is the inverse of the cumulative distribution function of the Gaussian distribution.\n",
    "\n",
    "**Suggestions**\n",
    "* Set your seed to 0.\n",
    "* Draw 1000 samples from a normal distribution with mean '$\\mu_1=10$', and standard deviation '$\\sigma_1=2.5$'\n",
    "* Draw 1000 samples from another normal distribution with standard deviation '$\\sigma_2=2.5$' with a different mean '$\\mu_2$' (vary the mean '$\\mu_2$' from 11 to 19 in steps of 2\n",
    "* For each value of the second mean '$\\mu_2$', calculate the $d'$, using the samples you have for each distribution using the samples from each distribution. (hint: you may want to use np.mean, and np.std)\n",
    "* For each value of the second mean '$\\mu_2$', calculate the $d'$, using the true mean and std of the distributions.  \n",
    "* Change the number of sample of each distribution from 100, 1000, and 10000. See how having more data leads to better estimates of $d'$. Particularly in real situations when we do not know the true underlying summary statistic (mean and standard deviation) of the noise and signal distributions, having more data will yield better estimates of $d'$.\n",
    "* Change the decision threshold such that you have 5 threshold values interspersed between the minimum of the noise distribution, up to the maximum of the signal distribution. \n",
    "* Print out the number of samples, threshold, estimated d_prime, true d_prime, and error \n",
    "* Calculate the Optimal threshold, Hit Rate, False Alarm rate, and bias '$c$' for each true decision-threshold and print it out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3381977916987391849() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3381977916987391849()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:01.078565Z",
     "start_time": "2018-06-12T11:25:01.017436Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### SOLUTION \n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "mu1, s = 10, 2.5\n",
    "n_values = [100, 1000, 10000]\n",
    "for i_n in range(len(n_values)):\n",
    "    n = n_values[i_n]\n",
    "    for mu2 in range(mu1 + 1, 2 * mu1, 2):\n",
    "    \n",
    "        dPrime = (mu2 - mu1) / np.sqrt(.5 * (s+s))\n",
    "    \n",
    "        noise = np.random.normal(mu1, s, size=n) \n",
    "        signal = np.random.normal(mu2, s, size=n) \n",
    "    \n",
    "        mu1_hat = np.mean(noise)\n",
    "        sd1_hat = np.std(noise)\n",
    "    \n",
    "        mu2_hat = np.mean(signal)\n",
    "        sd2_hat = np.std(signal)\n",
    "    \n",
    "        dPrime_hat = (mu2_hat - mu1_hat) / np.sqrt(.5 * (sd1_hat+sd2_hat))\n",
    "\n",
    "        data_min = np.min([noise, signal])\n",
    "        data_max = np.max([noise, signal])\n",
    "        \n",
    "        # decision criterion z\n",
    "        z_range = np.linspace(data_min, data_max, num=5)\n",
    "\n",
    "        FalseAlarmRate_samples = np.zeros_like(z_range)\n",
    "        HitRate_samples = np.zeros_like(z_range)\n",
    "    \n",
    "        print('Num samples: ' + str(n) + ', mu2: ' + str(mu2) + ', Estimated dprime: ' + str(round(dPrime_hat,2)) + ', True dprime: ' + str(round(dPrime,2)) + ', error: ' + str(round(dPrime-dPrime_hat,3))  )\n",
    "        \n",
    "        for idx, z in enumerate(z_range):\n",
    "\n",
    "            FalseAlarmRate_samples[idx] = np.mean(noise >= z)\n",
    "            HitRate_samples[idx] = np.mean(signal >= z)\n",
    "        \n",
    "    #       Could also calculate d' from FA and Hitrate as an example?\n",
    "    \n",
    "            print('True Threshold: ' + str(round(z,2)) + ', Optimal threshold: ' + str((mu1+((mu2-mu1)/2))) + ', bias c: ' + str(round(z-(mu1+((mu2-mu1)/2)),2)))\n",
    "        print(' ')\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Expected output ***\n",
    "\n",
    "![](./figures/expected_ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 3**\n",
    "\n",
    "In statistics, a receiver operating characteristic curve, i.e. ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "\n",
    "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm.\n",
    "\n",
    "ROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic decision making.\n",
    "\n",
    "--\n",
    "\n",
    "$d'$ can also be calculated with respect to the Area Under Curve (AUC) of the Receiver operating characteristic (ROC) curve, via\n",
    "\n",
    "\\begin{align*} d'=\\sqrt {2}Z\\left({\\mbox{AUC(ROC)}}\\right) \\end{align*}\n",
    "\n",
    "\n",
    "**Suggestions**\n",
    "* Set your seed to 0.\n",
    "* Draw 1000 samples from a normal distribution with mean '$\\mu_1=10$', and standard deviation '$\\sigma_1=2.5$'\n",
    "* Draw 1000 samples from another normal distribution with standard deviation '$\\sigma_2=2.5$' with a different mean '$\\mu_2$' (vary the mean '$\\mu_2$' from 11 to 19 in steps of 2\n",
    "* For each value of the second mean '$\\mu_2$', calculate the ROC curve for varying decision criterion, and plot all ROC curves in the same plot as dots.\n",
    "* For each value of '$\\mu_2$', also calculate the ROC curve based on the normal pdf (instead of samples from the pdf) and plot as lines (hint you may use scipy.stats.norm.cdf, scipy.stats.norm.sf). \n",
    "* Increase the number of sample of each distribution for 100, 500, and 1000. Look at how having more data changes the estimates.\n",
    "* For each value of '$\\mu_2$', calculate the sensitivity index d' using your calculation of the AUC and true distribution parameters.\n",
    "* Compare your estimate of the $d'$ calculated with the AUC, vs. that calculated with the equation in exercise 2.\n",
    "* Add axes labels, title, legends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4702783212221766911() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4702783212221766911()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:02.896233Z",
     "start_time": "2018-06-12T11:25:01.081801Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### SOLUTION \n",
    "\n",
    "random.seed(0)\n",
    "mu1, s = 10, 2.5\n",
    "\n",
    "n_values = [100, 500, 10000]\n",
    "for i_n in range(len(n_values)):\n",
    "    plt.figure();\n",
    "    n = n_values[i_n]\n",
    "    for mu2 in range(mu1 + 1, 2 * mu1, 2):\n",
    "    \n",
    "        dPrime = (mu2 - mu1) / np.sqrt(.5 * (s+s))\n",
    "    \n",
    "        no_flash = np.random.normal(mu1, s, size=n) \n",
    "        flash = np.random.normal(mu2, s, size=n)    \n",
    "\n",
    "        data_min = np.min([no_flash, flash])\n",
    "        data_max = np.max([no_flash, flash])\n",
    "\n",
    "        # decision criterion z\n",
    "        z_range = np.linspace(data_min, data_max, num=50)\n",
    "\n",
    "        falsePositiveRate_samples = np.zeros_like(z_range)\n",
    "        truePositiveRate_samples = np.zeros_like(z_range)\n",
    "\n",
    "        falsePositiveRate_distr = np.zeros_like(z_range)\n",
    "        truePositiveRate_distr = np.zeros_like(z_range)\n",
    "    \n",
    "        for idx, z in enumerate(z_range):\n",
    "\n",
    "            falsePositiveRate_samples[idx] = np.mean(no_flash >= z)\n",
    "            truePositiveRate_samples[idx] = np.mean(flash >= z)\n",
    "        \n",
    "            falsePositiveRate_distr[idx] = sp.stats.norm.sf(z, loc=mu1, scale=s)\n",
    "            truePositiveRate_distr[idx] = sp.stats.norm.sf(z, loc=mu2, scale=s) \n",
    "\n",
    "        plt.plot(falsePositiveRate_distr, truePositiveRate_distr, '-', color='black', linewidth=1)\n",
    "        plt.plot(falsePositiveRate_samples, truePositiveRate_samples, '.', label=\"$\\mu_2=%s, d'=%.1f$\" % (str(mu2), dPrime))\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlim(0,1,)\n",
    "    plt.ylim(0,1)\n",
    "    plt.title('ROC curves, n=' + str(n))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex3_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Drift Diffusion Model (DDM)\n",
    "\n",
    "Now that we have looked at the monkey's raw reaction time and accuracy data from this discrimination task, we can begin to think about how to model this data. As you saw in the lecture before, DDMs predict both RT and choice accuracy data and have been used to model behavior in this sort of sequential discimination task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short summary of the Drift diffusion model**\n",
    "\n",
    "The Drift Diffusion Model arises from the Sequential Probability Ratio Test in the limit where discretely presented evidence becomes continuously presented evidence. \n",
    "\n",
    "Let's take an example. Say a participant is shown a blurry stimulus that is either a face or a house, and ther participant needs to respond either 'face' or 'house' (2-AFC). Once a stimulus is displayed, the participant accumulates information over time by looking at the stimulus (the longer the participant looks at the stimulus, the more confident he/she will be that it is either a house or a face). The information accumulated with a drift-rate '$v$', and when the participant trace hits a decision-boundary '$0$' or '$a$', the participant responds 'house' or 'face' respectively. We can change the bias of a given participant '$z$', by changing the starting point of the accumulation trace with respect to the decision boundaries '$0$' or '$a$'. If we move '$z$' to be closer to '$a$' than to '$0$', then the participant will be more likely to respond 'face' (i.e. a bias in responding for faces).\n",
    "\n",
    "![](./figures/DDM.png)\n",
    "\n",
    "Mathematically, the DDM is given as a stochastic differential equation\n",
    "\n",
    "\\begin{eqnarray}\n",
    "dx = \\mu dt + \\sigma dW,\n",
    "\\end{eqnarray}\n",
    "\n",
    "where\n",
    "$\\mu$ : Drift rate, \n",
    "$\\sigma$ : Noise standard deviation, \n",
    "$dW$ : White Noise.\n",
    "\n",
    "Ignoring the boundary conditions, the distribution of increments of $x$ from time $s$ to time $t$ is a normal distribution $\\mathcal{N}$ with mean $\\mu (t-s)$ and standard deviation $\\sigma \\sqrt{t-s}$, $(s\\leq t)$:\n",
    "\\begin{eqnarray}\n",
    "X_t-X_s \\sim \\mathcal{N}(\\mu (t-s), \\sigma \\sqrt{t-s}).\n",
    "\\end{eqnarray}\n",
    "\n",
    "In discrete time form, the increment of the decision variable $\\Delta x$ after time $\\Delta t$ is\n",
    "\\begin{eqnarray}\n",
    "\\Delta x \\sim \\mathcal{N}(\\mu \\Delta t, \\sigma \\sqrt{\\Delta t}).\n",
    "\\end{eqnarray}\n",
    "\n",
    "Now consider two absorbing boundaries at $\\pm B$. A decision is committed once the decision variable reaches one of the boundaries. In other words, the decision variable is \"absorbed\" by the boundary.\n",
    "\n",
    "**References:**\n",
    "\n",
    "* Ratcliff, Roger. \"A theory of memory retrieval.\" Psychological review 85.2 (1978): 59.\n",
    "\n",
    "* Bogacz, Rafal, et al. \"The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks.\" Psychological review 113.4 (2006): 700."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this exercise** we'll write a function that simulates RTs and choices using a DDM with constant decision boundaries. We will plot this data, using the function written above, and in doing this we will begin to see how the model generated behavior compares to the monkey RT and choice data. In particular, we will play with some of the parameters of the DDM and look at the effects this has on the simulated data. In order to simulate the data, remember the key equations of the DDM:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\Delta x \\sim \\mathcal{N}(\\mu \\Delta t, \\sigma \\sqrt{\\Delta t}).\n",
    "\\end{eqnarray}\n",
    "\n",
    "which describes the incremental change in the decision variable $\\Delta x$ after time $\\Delta t$.\n",
    "\n",
    "Next, we will relax certain conditions of the DDM and see how this affects the simulated behavior. In particular, we will introduce time-varying drift and collapsing decision bounds. \n",
    "\n",
    "Finally, we will look at the analytical DDM and graphically compare its predictions to our simulated RT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 4: Constant bound DDM simulation***\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Write a function that simulates one trial of the DDM. The function should take parameters $\\mu$, $\\sigma$, and a boundary $B$ as inputs and return the choice, correctness, and reaction time for that trial, as well as the simulated trace of the decision variable (x in the equation above) and the times at which the decision variable was sampled in the simulation. \n",
    "* Plot the decision variable trajectories for 200 trials in the same figure with the following parameters: $\\mu=1.5 \\cdot 10^{-3}$, $\\sigma=0.05$, $B=1$.\n",
    "* (Optional) Change the parameters $\\mu, \\sigma$, and observe the change in the decision variable density.\n",
    "\n",
    "Hints: \n",
    "\n",
    "- adjust the alpha value of a plot to show more trajectories\n",
    "- to obtain reproducible results in code that uses random numbers, set the \"random seed\" (np.random.seed) to an integer value of your choice (we used the trial number as seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_18226566629612902203() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_18226566629612902203()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:02.952463Z",
     "start_time": "2018-06-12T11:25:02.899581Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_4841169392144285089() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_4841169392144285089()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Solution function\n",
    "\n",
    "def sim_DDM_constant(mu, sigma, B, dt=1, tMax=2500, seed=1):\n",
    "    \"\"\"\n",
    "    Function that simulates one trial of the constant bound DDM\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu: float\n",
    "        DDM drift rate\n",
    "    sigma: float\n",
    "        DDM standard-deviation\n",
    "    B: float\n",
    "        DDM boundary\n",
    "    dt: float, optional\n",
    "        time step in msec with which DDM will be integrated\n",
    "    tMax: float, optional\n",
    "        DDM is integrated from t=0 to t=tMax [in msec], should be multiple of dt\n",
    "    seed: integer, optional\n",
    "        random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    choice: categorical\n",
    "        indicates whether left or right boundary was reached by decision variable\n",
    "    correct: bool\n",
    "        whether or not the left boundary (which is assumed to be the target boundary) was chosen\n",
    "    rt: float\n",
    "        reaction time in msec\n",
    "    dvTrace: list\n",
    "        trace of decision variable\n",
    "    tTrace: array_like\n",
    "        times at which decision variable was sampled in the simulation\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Additional parameters\n",
    "    n_max    = tMax / dt   # maximum number of time steps\n",
    "    tSimu   = dt * np.arange(1,n_max)\n",
    "    \n",
    "    sigma_dt = sigma * np.sqrt(dt)\n",
    "    mu_dt    = mu * dt\n",
    "    \n",
    "    # Initialize decision variable x\n",
    "    x = 0\n",
    "    \n",
    "    # Storage\n",
    "    tTrace = [0]\n",
    "    dvTrace = [x]\n",
    "    \n",
    "    # Looping through time\n",
    "    for t in tSimu:\n",
    "        x += mu_dt + sigma_dt * np.random.randn() # internal decision variable x\n",
    "        \n",
    "        tTrace.append(t)\n",
    "        dvTrace.append(x) # save new x\n",
    "\n",
    "        # check boundary conditions\n",
    "        if x > B:\n",
    "            rt = t  \n",
    "            choice = 'left'\n",
    "            break\n",
    "        if x < -B:\n",
    "            rt = t\n",
    "            choice = 'right'\n",
    "            break\n",
    "    else: # executed if no break has occurred in the for loop\n",
    "        # If no boundary is hit before maximum time, \n",
    "        # choose according to decision variable value\n",
    "        rt = t\n",
    "        choice = 'left' if x > 0 else 'right'\n",
    "        \n",
    "    correct = (choice == 'left') # assumes left choice is correct\n",
    "    \n",
    "    return choice, correct, rt, dvTrace, tTrace\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n",
    "\n",
    "# Loop over trials, for each trial call your function, plot trajectories\n",
    "\n",
    "mu, sigma, B = 1.5*1e-3, 0.05, 1\n",
    "plt.figure()\n",
    "for i_trial in np.arange(200):\n",
    "    choice, correct, rt, dvTrace, tTrace = sim_DDM_constant(mu, sigma, B, seed=i_trial)\n",
    "    plt.plot(tTrace, dvTrace, '-', color='k', alpha=0.1)\n",
    "    \n",
    "# beautify plot\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Decision variable')\n",
    "plt.ylim((-B,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "![](./figures/expected_ex4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 5: Reaction time distribution***\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Simulate the DDM for 5000 trials with $\\mu=0.0015, \\sigma=0.05, B=1$.\n",
    "* Plot the reaction time distribution, separating correct from error trials (use the function provided below)\n",
    "* (optional) Edit the function 'plot_rt_distribution' so that you have the raw traces of sim_DDM sandwiched between the distribution of correct RTs in blue, and incorrect RTs in red (see expected output; hint: you may want to look-up subplots in matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2592451403863366814() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2592451403863366814()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:04.257432Z",
     "start_time": "2018-06-12T11:25:04.251383Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_8529752868459067080() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_8529752868459067080()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Solution function\n",
    "\n",
    "def  plot_rt_distribution (rt1, rt0, bins=None):\n",
    "    '''\n",
    "    # Function that takes RT data as input and plots a histogram\n",
    "\n",
    "    rt1/rt0 : array of reaction time for correct/error trials\n",
    "    bins: if given, the bins for plotting\n",
    "    '''\n",
    "    if bins is None:\n",
    "        maxrt = max((max(rt1),max(rt0)))\n",
    "        bins = np.linspace(0,maxrt,26)\n",
    "    count1, bins_edge = np.histogram(rt1, bins=bins)\n",
    "    count0, bins_edge = np.histogram(rt0, bins=bins)\n",
    "    n_rt = len(rt0) + len(rt1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(bins_edge[:-1], count1/n_rt, np.diff(bins_edge), color='blue', edgecolor='white')\n",
    "    plt.bar(bins_edge[:-1], -count0/n_rt, np.diff(bins_edge), color='red', edgecolor='white')\n",
    "    \n",
    "    titletxt = 'Prop. correct {:0.2f}, '.format(sum(count1)/n_rt)\n",
    "    titletxt += 'Mean RT {:0.0f}/{:0.0f} ms'.format(np.mean(rt1),np.mean(rt0))\n",
    "    \n",
    "    plt.ylabel('Proportion')\n",
    "    plt.xlabel('Reaction Time')\n",
    "    plt.title(titletxt)\n",
    "    plt.xlim((bins.min(),bins.max()))\n",
    "    \n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:07.521430Z",
     "start_time": "2018-06-12T11:25:04.259287Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "mu, sigma, B = 0.0015, 0.05, 1\n",
    "n_trial = 5000\n",
    "rts      = np.zeros(n_trial)\n",
    "corrects = np.zeros(n_trial)\n",
    "for i_trial in range(n_trial):\n",
    "    choice, correct, rt, _, _ = sim_DDM_constant(mu, sigma, B, seed=i_trial)\n",
    "    rts[i_trial] = rt\n",
    "    corrects[i_trial] = correct\n",
    "    \n",
    "# Plot the RT distributions\n",
    "plot_rt_distribution(rts[corrects==1], rts[corrects==0],np.linspace(0,2500,51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T17:06:48.293804Z",
     "start_time": "2018-06-07T17:06:48.286861Z"
    }
   },
   "source": [
    "**Expected Output**\n",
    "![](./figures/expected_ex5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 6: Analytical solution of classical DDM***\n",
    "\n",
    "One can obtain an analytic solution for the reaction time distribution of the drift diffusion model, which we provide here. Don't worry about the inner working of the function, just how to use it.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* import the function 'analytic_ddm' from the ddm module in the 'src' folder.\n",
    "* look at the docstring of the function to see what parameters it takes and what it returns (in the notebook you can append '?' to the function name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_836341680636475175() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_836341680636475175()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:07.572177Z",
     "start_time": "2018-06-12T11:25:07.523798Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "from src.ddm import analytic_ddm\n",
    "\n",
    "analytic_ddm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 7: Comparison between analytic and simulated solution***\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Compare the analytical solution with simulation results (use 10,000 trials): $\\mu=1e-3, \\sigma=0.05, B=1$.\n",
    "* Compare the time taken by the simulation and analytical calculation.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- When comparing analytical and simulated RT histograms, make sure the normalizations of the histograms are consistent\n",
    "- Useful function: time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_1428881769347889721() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_1428881769347889721()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:25:14.548516Z",
     "start_time": "2018-06-12T11:25:07.574772Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Solution \n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "mu, sigma, B = 0.0015, 0.05, 1\n",
    "\n",
    "# Simulation results\n",
    "n_trial  = 10000\n",
    "rts      = np.zeros(n_trial)\n",
    "corrects = np.zeros(n_trial)\n",
    "t_start  = time.time()\n",
    "for i_trial in range(n_trial):\n",
    "    choice, correct, rt, _, _ = sim_DDM_constant(mu, sigma, B, seed=i_trial)\n",
    "    rts[i_trial] = rt\n",
    "    corrects[i_trial] = correct\n",
    "print('Time taken: ' + str(time.time() - t_start) + 's (Simulations results)')\n",
    "\n",
    "bins = np.linspace(0,2500,51)\n",
    "plot_rt_distribution(rts[corrects==1], rts[corrects==0], bins)\n",
    "\n",
    "# Analytical results\n",
    "teval = np.arange(0,bins[-1],1)[1:]\n",
    "t_start = time.time()\n",
    "dist_cor, dist_err = analytic_ddm(mu, sigma, B, teval)\n",
    "print('Time taken: ' + str(time.time() - t_start) + 's (Analytical results)')\n",
    "\n",
    "plt.plot(teval, dist_cor*(bins[1]-bins[0]), color = 'blue', lw=2)\n",
    "plt.plot(teval,-dist_err*(bins[1]-bins[0]), color = 'red', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "![](./figures/expected_ex7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Signal Detection Theory & Drift Diffusion Modelling ",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
