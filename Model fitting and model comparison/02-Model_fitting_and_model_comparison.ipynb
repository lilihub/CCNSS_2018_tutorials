{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCNSS 2018 module 2\n",
    "# Tutorial 2 - Model fitting and model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please execute the cell below to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:10:08.577534Z",
     "start_time": "2018-06-12T11:10:07.437578Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows to call the function 'hide_toggle' that shows/hides solutions for each exercise\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Show/hide Solution below'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' '\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "In this notebook we'll look at *model fitting* using the Drift Diffusion Model (DDM) we developped in Tutorial 1. That is, we will attempt to recover the parameters that generated the data with the DDM. We will then have a look at *model comparison* and *model selection*.\n",
    "\n",
    "Model fitting:\n",
    "\n",
    "- Ordinary least squares (OLS)\n",
    "- Likelihood, and Maximum Likelihood Estimation (MLE)\n",
    "    - Grid search approximation\n",
    "    - Gradient Descent optimisation\n",
    "\n",
    "Model Comparison:\n",
    "\n",
    "- Model Selection using:\n",
    "    - Bayesian Information Criterion (BIC)\n",
    "    - Akaike Information Criterion (AIC)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares (OLS) Regression\n",
    "\n",
    "We have data pairs $(x_i,y_i)$ that we think are linearly related but we are not sure what the slope or intercept is that best characterizes this relationship. To find this, we fit the data with a linear model\n",
    "\n",
    "\\begin{align*} \\hat{y}_i = \\beta_1 x_i + \\beta_0 \\end{align*}\n",
    "\n",
    "and estimate the best fitting parameters by minimizing the mean squared error (MSE). That is, we want to find the parameters $\\beta_0$ and $\\beta_1$ such that the line fits the data as best as possible. To do so, we will calculate the squared error (i.e. squared distance) between the line and the data-points, and choose the parameters that gives us the least error possible (i.e. the minimum error across all data points):\n",
    "\n",
    "\\begin{align*} \\sum_i(y_i - \\hat{y}_i)^2 = \\sum_i (y_i-\\beta_1 x_i+\\beta_0)^2 \\end{align*}\n",
    "\n",
    "For the case of linear regression, there is actually an analytical solution:\n",
    "\n",
    "\\begin{align*} \\beta_1 = \\frac{cov(x,y)}{var(x)} \\end{align*}\n",
    "\n",
    "\\begin{align*} \\beta_0 = \\bar{y} - \\hat{\\beta_1} x \\end{align*}\n",
    "\n",
    "but we will use a more general optimization library to start familiarizing ourselves with these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 1: OLS***\n",
    "\n",
    "We will generate 100 data points with a linear relationship, and attempt to recover the parameters that generated the data.\n",
    "\n",
    "**Suggestions**\n",
    "* Set the seed to 0\n",
    "* Generate N = 100 data pairs $(x_i,y_i)$ using a linear model with normally distributed noise $\\epsilon = 1$ and your choice of slope $\\beta_1=1$ and intercept $\\beta_0=0.5$ parameters.\n",
    "* Calculate the analytical estimate for the OLS regression\n",
    "* Write a function that returns the mean square error (MSE) for any parameter values.\n",
    "* Use an optimization library to numerically find the parameters that minimize the MSE and compare these to the true parameters of the generative model (hint: you may want to use the 'scipy.optimize.minimize' function.\n",
    "* Plot the data, as well as the anlytical and numerical OLS estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_451017212847122032() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_451017212847122032()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:10:14.053085Z",
     "start_time": "2018-06-12T11:10:13.494724Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# Generate the data\n",
    "beta1 = 1\n",
    "beta0 = 0.5\n",
    "sigma = 1\n",
    "xdata = np.random.randn(100)\n",
    "eps   = sigma * np.random.randn(100)\n",
    "ydata = beta1*xdata + beta0 + eps\n",
    "\n",
    "# Compute the analytical solutions\n",
    "beta1_est = np.cov(xdata,ydata)[0,1] / np.var(xdata)\n",
    "beta0_est = np.mean(ydata) - beta1_est*np.mean(xdata)\n",
    "print('Analytical B0: ' + str(beta0_est), ', B1: ' + str(beta1_est))\n",
    "\n",
    "# Function that returns the MSE\n",
    "def get_MSE(params):   \n",
    "    y_hat = params[1]*xdata + params[0]    \n",
    "    return np.sum((ydata-y_hat)**2)\n",
    "\n",
    "# Optimization (recovering the parameters)\n",
    "initial_guess = [2,1]\n",
    "res = minimize(get_MSE, initial_guess)\n",
    "res.x\n",
    "print('Optimization B0: ' + str(res.x[0]), ', B1: ' + str(res.x[1]))\n",
    "\n",
    "plt.plot(xdata, ydata, 'o')\n",
    "xs = np.array([xdata.min(), xdata.max()])\n",
    "plt.plot(xs, beta0_est + beta1_est*xs,'-.b',LineWidth=2,label='Analytical Solution')\n",
    "plt.plot(xs, res.x[0] + res.x[1]*xs,'--r',LineWidth=2,label='Optimization Solution')\n",
    "plt.ylabel('Y');\n",
    "plt.xlabel('X');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-11T13:53:58.185789Z",
     "start_time": "2018-06-11T13:53:58.179019Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-11T13:55:01.172566Z",
     "start_time": "2018-06-11T13:55:01.160995Z"
    }
   },
   "source": [
    "## Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "We can also fit the model to the data using Maximum Likelihood Estimation methods. To do this, we take the following generative model for the data:\n",
    "\n",
    "\\begin{align*} \\hat{y}_i = \\beta_1 x_i + \\beta_0 + \\epsilon \\end{align*}\n",
    "\n",
    "where $\\epsilon\\sim \\mathcal{N}(\\mu=0,\\sigma^2)$ is a normally distributed random variable with mean 0 and variance $\\sigma^2$ and $y\\sim \\mathcal{N}(\\mu=(\\beta_1 x+\\beta_0),\\sigma^2)$.\n",
    "\n",
    "The probability distribution of $y$ given $x$ is then given by: \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\\\\n",
    "p(y_i|x_i,\\beta_1,\\beta_0) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[-(y_i-(\\beta_1 x_i+\\beta_0))^2/(2\\sigma^2)\\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "For a pair $(x_i,y_i)$, the log likelihood of observation $y_i$ is \n",
    "\\begin{eqnarray}\n",
    "\\log p(y_i|x_i,a,b)\n",
    "= \\log \\left[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[-(y_i-(\\beta_1 x_i+\\beta_0))^2/(2\\sigma^2)\\right]\\right] \\\\\n",
    "= \\log \\left[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right] -(y_i-(\\beta_1 x_i+\\beta_0))^2/(2\\sigma^2)\n",
    "\\end{eqnarray}\n",
    "\n",
    "That is: When $\\epsilon$ is normally distributed, maximizing the total log likelihood of the data is equivalent to minimizing the mean squared error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 2: MLE - Grid-Search***\n",
    "\n",
    "Using the generated 100 data points from EXERCISE 1, calculate the Likelihood of the data given the parameters. That is:\n",
    "\n",
    "\\begin{align*} p\\left(Data_{y_i} \\mid \\beta_1,\\beta_0 \\right) \\end{align*}\n",
    "\n",
    "We will then extract the maximum of the log likelihood (or inversely, the minimum of the negative log likelihood). That is, the parameters that maximizes the chance of observing the data:\n",
    "\n",
    "\\begin{align*} p\\left(\\beta_1,\\beta_0 \\mid Data \\right) = \\arg \\max \\sum_{y_i} \\log p\\left(Data_{y_i} \\mid \\beta_1,\\beta_0 \\right)\\end{align*}\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Write a function that returns the total negative of the log likelihood for any parameter values.\n",
    "* Search (loop) through parameter values ranging from -4 to 4 in increments of 0.01, calculate and store the negative log likelihood for each parameter value of the loop.\n",
    "* Print the parameters found for $\\beta_0$, and $\\beta_1$ to the true parameters.\n",
    "* Print the error between the true parameters and those found using optimization, and time the function took to compute the likelihood for all pairs of parameter values.\n",
    "* Plot the log likelihood as a function of parameter values ($\\beta_0$ and $\\beta_1$) using a heatmap, and mark the value with lowest negative log likelihood (hint: you may want to use the function `imshow`, or `contourf`)\n",
    "    * Alternatively you could try to make fancier 3D-plots using : `plot_surface`, or `plot_wireframe`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2398409205547195925() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2398409205547195925()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:12:06.075383Z",
     "start_time": "2018-06-12T11:11:48.816057Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "\n",
    "# Function that returns the negative ll (nll)\n",
    "def get_nll(params):\n",
    "    y_hat = params[0]*xdata + params[1]\n",
    "    \n",
    "    # calculate the likelihood\n",
    "    likelihood = 1/np.sqrt(2*np.pi*sigma**2)*np.exp(-(ydata-y_hat)**2/(2*sigma**2))\n",
    "    \n",
    "    return -np.sum(np.log(likelihood+1e-100)) # keep l > 0 so can take log\n",
    "\n",
    "step_x0 = 0.01\n",
    "n_x0=len(np.arange(-4,4,step_x0))\n",
    "beta1_all = np.tile(np.arange(-4,4,step_x0),n_x0)\n",
    "beta0_all = np.repeat(beta1_all,n_x0)\n",
    "\n",
    "x = y = np.arange(-4, 4, step_x0)\n",
    "X, Y = np.meshgrid(x, y) \n",
    "\n",
    "t_start  = time.time()\n",
    "\n",
    "ll_list = list()\n",
    "for beta1_all_, beta0_all_ in zip(beta1_all,beta0_all):\n",
    "    ll_list.append(-get_nll([beta1_all_, beta0_all_]))\n",
    "\n",
    "t_end=time.time()\n",
    "\n",
    "ll_list = np.array(ll_list)\n",
    "extent = [np.min(beta1_all),np.max(beta1_all),np.min(beta0_all),np.max(beta0_all)]\n",
    "\n",
    "ind = np.unravel_index(np.argmax(ll_list.reshape((n_x0,n_x0)), axis=None), ll_list.reshape((n_x0,n_x0)).shape)\n",
    "print('Estimated B0: '+ str(Y[ind]) + ', estimated B1: ' +str(X[ind]) + ', estimated nLL: ' +str(ll_list.reshape((n_x0,n_x0))[ind]) )\n",
    "print('Rounded Error B0: ' + str(round(Y[ind]-beta0,2)) + ' , rounded error B1: ' + str(round(X[ind]-beta1,2)) + ' , Time taken : ' + str(round(t_end-t_start,2)) + ' seconds')\n",
    "\n",
    "# Plot using imshow()\n",
    "plt.figure()\n",
    "plt.title('Likelihood plot using: `imshow`')\n",
    "plt.imshow(ll_list.reshape((n_x0,n_x0)), origin='lower',\n",
    "            cmap='hot', extent=extent, aspect='auto')\n",
    "plt.axvline(beta1,linestyle='-.',color='k')\n",
    "plt.axhline(beta0,linestyle='-.',color='k')\n",
    "plt.plot(beta1,beta0,'ok')\n",
    "plt.xlabel(r'$\\beta_1$')\n",
    "plt.ylabel(r'$\\beta_0$')\n",
    "plt.colorbar(label='Log Likelihood')\n",
    "\n",
    "# Plot using contourf()\n",
    "plt.figure()\n",
    "plt.title('Likelihood plot using: `contourf`')     \n",
    "plt.contourf(X, Y, ll_list.reshape((n_x0,n_x0)), 40, cmap=plt.cm.bone)\n",
    "plt.axvline(beta1,linestyle='-.',color='k')\n",
    "plt.axhline(beta0,linestyle='-.',color='k')\n",
    "plt.plot(beta1,beta0,'ok')\n",
    "plt.xlabel(r'$\\beta_1$')\n",
    "plt.ylabel(r'$\\beta_0$')\n",
    "plt.colorbar(label='Log Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected output***\n",
    "\n",
    "![](./figures/expected_ex2_1.png)\n",
    "\n",
    "![](./figures/expected_ex2_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_15496983222630434079() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_15496983222630434079()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional question: use plot_surface() and wire_frame()\n",
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:14:13.357861Z",
     "start_time": "2018-06-12T11:14:11.590718Z"
    }
   },
   "outputs": [],
   "source": [
    "### --- Solution: OPTIONAL QUESTION \n",
    "\n",
    "# Plot using plot_surface()\n",
    "fig = plt.figure()\n",
    "plt.title('Likelihood plot using: `plot_surface`')\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(X, Y, ll_list.reshape((n_x0,n_x0)), cmap=plt.cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "plt.xlabel(r'$\\beta_1$')\n",
    "plt.ylabel(r'$\\beta_0$')\n",
    "ax.set_zlabel('Log Likelihood')\n",
    "\n",
    "# Plot using wire_frame()\n",
    "fig = plt.figure()\n",
    "plt.title('Likelihood plot using: `contourf`')\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_wireframe(X, Y, ll_list.reshape((n_x0,n_x0)), color='blue', rstride=20, cstride=20)\n",
    "plt.xlabel(r'$\\beta_1$')\n",
    "plt.ylabel(r'$\\beta_0$')\n",
    "ax.set_zlabel('Log Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:09:15.036165Z",
     "start_time": "2018-06-12T11:09:15.030124Z"
    }
   },
   "source": [
    "***(Optional) Expected Output***\n",
    "\n",
    "![](./figures/expected_ex2_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 3: MLE - Optimization (Gradient Descent)***\n",
    "\n",
    "Instead of looping through the combination of all the parameter values in a loop. We will be using gradient descent (i.e. 'optimization' methods), to extract the maximum of the log likelihood (or inversely, the minimum of the negative log likelihood). That is, the parameters that maximizes the chance of observing the data:\n",
    "\n",
    "\\begin{align*} p\\left(\\beta_1,\\beta_0 \\mid Data \\right) = \\arg \\max \\sum_{y_i} \\log p\\left(Data_{y_i} \\mid \\beta_1,\\beta_0 \\right)\\end{align*}\n",
    "\n",
    "Intuitively, you can think of gradient descent optimization as follows: \n",
    "The optimization algorithm calculates the slope (i.e. derivative) of a function at a given point. In our case, we want to maximize the likelihood (i.e. find the top of the log-likelihood 'hill'). That is, the optimization function will calculates the gradient (derivative) of the log-likelihood given the parameter values, and 'ascend' the likelihood function (or 'descend' the negative log-likelihood) until it finds a derivative of 0 (that is no slope --> it found a minima or maxima, up until convergence to some threshold)\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Use an optimization library to numerically find the parameters that minimize the negative log likelihood (or equivalently, maximize the log likelihood of the data given the model). Tip: Use the minimize function from the scipy.optimize module.\n",
    "* Print the parameters found using the optimization function\n",
    "* Print the error between the true parameters and those found using optimization, and time the function took to converge\n",
    "* Compare the parameters found using optimization to those found with grid-search\n",
    "* Compare the time it took to find the parameters with optimization vs. grid-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_10093634326215478738() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_10093634326215478738()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:17:38.183594Z",
     "start_time": "2018-06-12T11:17:38.175700Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "# Optimization (find parameters that minimize nll)\n",
    "initial_guess = [1,1]\n",
    "t_start_optim = time.time()\n",
    "res = minimize(get_nll, initial_guess)\n",
    "t_end_optim = time.time()\n",
    "\n",
    "print('Estimated B0: '+ str(res.x[1]) + ', estimated B1: ' +str(res.x[0]) + ', estimated nLL: ' +str(res.fun) )\n",
    "print('Rounded Error B0: ' + str(round(res.x[1]-beta0,2)) + ' , rounded error B1: ' + str(round(res.x[0]-beta1,2)) + ' , Time taken : ' + str(round(t_end_optim-t_start_optim,8)) + ' seconds')\n",
    "print(' ')\n",
    "print('Grid-search took ' + str((t_end-t_start)/(t_end_optim-t_start_optim)) + ' times longer than using the `minimize` function')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex3_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Fitting the DDM\n",
    "\n",
    "Now that we have looked at model fitting for a simple case, we can try to fit the DDM to the data from last class in order to find the best fitting mean, noise and boundary parameters.\n",
    "\n",
    "We will test our ability to recover the parameters of the model on simulated data for which we set the parameters.\n",
    "\n",
    "Once we are convinced that we can recover the parameters on simulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-11T19:19:14.088944Z",
     "start_time": "2018-06-11T19:19:14.081394Z"
    }
   },
   "source": [
    "***EXERCISE 4: Fit DDM to simulated data***\n",
    "    \n",
    "***Suggestions***\n",
    "\n",
    "* Set your seed to 0\n",
    "* Generate 5000 trials of simulated RT data using the constant bound DDM function ($\\mu = 0.0015, \\sigma = 0.05, B = 1$)\n",
    "* Plot the simulated RT data using your plot function from yesterday\n",
    "\n",
    "Tip: We will import a data simulation function `sim_DDM_constant`, a plotting function `plot_rt_distribution` and a function that computes the analytic DDM and returns the (RG) `analytic_ddm` from the module ddm. You can use this module or you can use your own based on the work from the last tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:19:05.290566Z",
     "start_time": "2018-06-12T11:19:05.283372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9409005416102392390() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9409005416102392390()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:19:10.060604Z",
     "start_time": "2018-06-12T11:19:07.557148Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "from src.ddm_tutorial1 import sim_DDM_constant, analytic_ddm, plot_rt_distribution\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# Set parameters and initialize \n",
    "mu, sigma, B = 0.0015, 0.05, 1\n",
    "n_trial      = 5000\n",
    "rts_sim      = np.zeros(n_trial)\n",
    "corrects_sim = np.zeros(n_trial)\n",
    "\n",
    "# Simulate reaction time and performance data using the DDM constant bound model\n",
    "for i_trial in range(n_trial):\n",
    "    choice,correct,rt,dvTrace,tTrace = sim_DDM_constant(mu, sigma, B, seed=i_trial)\n",
    "    rts_sim[i_trial] = rt\n",
    "    corrects_sim[i_trial] = correct\n",
    "\n",
    "# Plot the RT data, separating correct from incorrect trials\n",
    "bins = np.linspace(0,2500,26)\n",
    "plot_rt_distribution(rts_sim[corrects_sim==1], rts_sim[corrects_sim==0], bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected output***\n",
    "\n",
    "![](./figures/expected_ex4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-11T19:29:32.082920Z",
     "start_time": "2018-06-11T19:29:32.076340Z"
    }
   },
   "source": [
    "***EXERCISE 5: Compute likelihood from analytic DDM***\n",
    "\n",
    "In this exercise we will calculate the likelihood given parameters for the Drift Diffusion Model.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Implement the calculation of the DDM negative log-likelihood by completing the function below.\n",
    "* Use the `analytic_ddm` function from the module `ddm_tutorial1` to calculate the log-likelihood for a correct trial where RT is $500ms$, $\\mu=0.0015$ and $B=1$.\n",
    "* What's the log-likelihood for an incorrect trial with otherwise identical parameters?\n",
    "* What's the analytical log-likelihood of the decision-variable trajectory from the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3367584038984917796() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3367584038984917796()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "def get_nll_ddm(mu, sigma, B, rts, corrects):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the analytical DDM\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 2: 1st entry is mu (drift rate), 2nd is B (boundary)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    sigma : float\n",
    "        DDM standard deviation\n",
    "    rts : array_like of floats\n",
    "        reaction times for which the likelihood will be evaluated\n",
    "    corrects: array_like of bools, same length as rts\n",
    "        indicates for each rt if it was a correct trial\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:20:20.019473Z",
     "start_time": "2018-06-12T11:20:20.009963Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution to function\n",
    "\n",
    "def get_nll_ddm(mu, sigma, B, rts, corrects):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the analytical DDM\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 2: 1st entry is mu (drift rate), 2nd is B (boundary)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    sigma : float\n",
    "        DDM standard deviation\n",
    "    rts : array_like of floats\n",
    "        reaction times for which the likelihood will be evaluated\n",
    "    corrects: array_like of bools, same length as rts\n",
    "        indicates for each rt if it was a correct trial\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "    \n",
    "    # Make sure rts and corrects are numpy arrays\n",
    "    rts = np.array(rts) # make sure rts is np.ndarray\n",
    "    corrects = np.array(corrects)\n",
    "\n",
    "    # Create a vector of values where we will evaluate the analytic_ddm\n",
    "    teval = np.unique(rts)\n",
    "    \n",
    "    # Evaluate the analytic ddm\n",
    "    dist_cor, dist_err = analytic_ddm(mu, sigma, B, teval, b_slope=0)\n",
    "\n",
    "    # init log-likelihood (LL)\n",
    "    ll = 0\n",
    "\n",
    "    # For each RT determine the LL from the corresponding\n",
    "    # correct or incorrect analytical RT proabability distribution\n",
    "    # and sum LLs over occurrences of the RT\n",
    "    \n",
    "    # - correct trial RTs\n",
    "    rts_cor = rts[corrects == True]\n",
    "    rts_cor_unique, counts = np.unique(rts_cor, return_counts=True)\n",
    "    for rt, count in zip(rts_cor_unique, counts):\n",
    "        ll += count * np.log(dist_cor[np.where(teval == rt)[0][0]]) \n",
    "\n",
    "    # - incorrect trial RTs\n",
    "    rts_err = rts[corrects == False]\n",
    "    rts_err_unique, counts = np.unique(rts_err, return_counts=True)\n",
    "    for rt, count in zip(rts_err_unique, counts):\n",
    "        ll += count * np.log(dist_err[np.where(teval == rt)[0][0]])\n",
    "        \n",
    "    # return negative LL\n",
    "    return -ll\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:20:22.571122Z",
     "start_time": "2018-06-12T11:20:22.544548Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution to exercise\n",
    "\n",
    "# 500msec correct trial\n",
    "print('Log-Likelihood using analytical DDM, correct trial, 500ms: ' +  str(-get_nll_ddm(1.5e-3, 0.05, 1, np.array([500]), np.array([True]))))\n",
    "\n",
    "# 3. 500msec incorrect trial\n",
    "print('Log-Likelihood using analytical DDM, incorrect trial, 500ms: ' + str(-get_nll_ddm(1.5e-3, 0.05, 1, np.array([500]), np.array([False]))))\n",
    "\n",
    "# 4. LL of previous exercise's decision-variable trajectory\n",
    "print('Log-Likelihood using analytical DDM, using decision-variable trajectory: ' + str(-get_nll_ddm(1.5e-3, 0.05, 1, rts_sim, corrects_sim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 6: Fit DDM to simulated reaction time data***\n",
    "\n",
    "Once you are able to evaluate your likelihood function at various parameter values, it's time to fit the simulated data. The goal here is to pass the negative log likelihood to an optimizer that will find the parameters to minimize the total negative log likelihood.\n",
    "\n",
    "Note that optimizers tend to work better when parameters have the same order of magnitude. Also, the optimization function that we are going to use, `scipy.optimize.minimize`, requires that all parameters that are optimized over are packed into a vector and that this vector is the first argument of the objective function.\n",
    "\n",
    "- Write a wrapper function that's exactly like `get_nll_ddm`, except that it takes as first argument the vector $(1000 \\mu,B)$.\n",
    "\n",
    "Remember that this will mean rescaling the parameters returned by the optimizer in future exercises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17055177448301731286() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17055177448301731286()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:20:59.483161Z",
     "start_time": "2018-06-12T11:20:59.479192Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "# parameters = (1000mu, B)\n",
    "get_nll_ddm_wrapper = lambda parameters, sigma, rts, corrects: get_nll_ddm(parameters[0]/1000., sigma, parameters[1], rts, corrects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Suggestions***\n",
    "\n",
    "* Use the optimizer `minimize` on your negative log likelihood function to maximize the log likelihood of the simulated data. Again $\\sigma$ will be fixed at 0.05. \n",
    "* Is the optimization succesful? If yes, you should see \"message: 'Optimization terminated successfully.'\" in the output. If not, consider using a bounded optimization (check out the bounds input to the function and use method 'SLSQP'). $mu$ and $B$ should be positive.\n",
    "* Compare the simulated data with the fitted distribution. To do so, use the analytic_ddm function with the fitted parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17500556480569397710() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17500556480569397710()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:21:03.852416Z",
     "start_time": "2018-06-12T11:21:03.084112Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rts_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-700220ba21b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# The lambda expression allows us the pass different datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m res = minimize(get_nll_ddm_wrapper, \n\u001b[0;32m---> 11\u001b[0;31m                \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrts_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                method='SLSQP', x0=x0, bounds=bounds)\n\u001b[1;32m     13\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;31m# get log likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rts_sim' is not defined"
     ]
    }
   ],
   "source": [
    "### Solution\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "x0 = [1,2] # Initial guess\n",
    "bounds = [(0.3,1.5),(0.5,3)] # Optimization bounds\n",
    "sigma = 0.05 # always fixed\n",
    "\n",
    "# The lambda expression allows us the pass different datasets\n",
    "res = minimize(get_nll_ddm_wrapper, \n",
    "               args=(sigma, rts_sim, corrects_sim),\n",
    "               method='SLSQP', x0=x0, bounds=bounds)\n",
    "ll = -res.fun # get log likelihood\n",
    "\n",
    "print(res.message)\n",
    "print('Loglikelihood is :' + str(round(ll,2)))\n",
    "\n",
    "# Plotting the simulated data\n",
    "bins = np.linspace(0,2500,51)\n",
    "plot_rt_distribution(rts_sim[corrects_sim==1], rts_sim[corrects_sim==0], bins)\n",
    "\n",
    "# Plotting the analytical results\n",
    "teval = np.arange(0,bins[-1],1)[1:]\n",
    "mu = res.x[0]/1000 # scaling\n",
    "b = res.x[1]\n",
    "# sigma is as before\n",
    "dist_cor, dist_err = analytic_ddm(mu, sigma, b, teval)\n",
    "\n",
    "plt.plot(teval, dist_cor*(bins[1]-bins[0]), color = 'blue')\n",
    "plt.plot(teval,-dist_err*(bins[1]-bins[0]), color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected output***\n",
    "\n",
    "![](./figures/expected_ex6_1.png)\n",
    "\n",
    "![](./figures/expected_ex6_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "We will use the $BIC$ (Bayesian Information Criterion) to compare models:\n",
    "\n",
    "\\begin{align*} -2 \\log p(M|y) \\approx -2\\ln(L) + k\\ln(n) \\equiv BIC \\end{align*}\n",
    "\n",
    "where \n",
    "                            * $M$ is the model under consideration, \n",
    "                            * $L$ the likelihood for model $M$,\n",
    "                            * $y$ the observed data, \n",
    "                            * $k$ the number of free parameters, \n",
    "                            * $n$ the number of data points (observations)\n",
    "\n",
    "and the approximation holds for large $n$.\n",
    "\n",
    "The $BIC$ penalizes more complex models with more parameters. Specifically, in our context, the BIC penalizes the non-decision time model for its extra parameter.\n",
    "\n",
    "Note that a lower BIC is better and in general a difference of BIC 10 or more is good evidence for the model with the lower BIC.\n",
    "\n",
    "***EXERCISE 7 : Calculating the BIC***\n",
    "\n",
    "We will compute the BIC for three models (one full model), one where we fix the $B=0.5$ to a constant, and one where $mu=0$ is fixed (you can think of this as a Null model)\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Fit the models with Compare the BIC for the three models (you can constrain parameter values by restricting the bounds of parameters to be optimized)\n",
    "* Which model has the smaller BIC (the smaller the better)?\n",
    "* Plot the BICs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6200161194134101145() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6200161194134101145()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:22:20.164018Z",
     "start_time": "2018-06-12T11:22:17.910611Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "N_data = len(rts_sim)\n",
    "bic=list();\n",
    "\n",
    "# Fit data to full model\n",
    "res_full = minimize(get_nll_ddm_wrapper, \n",
    "               args=(sigma, rts_sim, corrects_sim),\n",
    "               method='SLSQP', x0=x0, bounds=[(0.3,1.5),(0.5,3)])\n",
    "ll_full = -res_full.fun # get log likelihood\n",
    "bic.append(-2*ll_full+2*np.log(N_data))\n",
    "\n",
    "# Fit data to restricted B model\n",
    "res_B = minimize(get_nll_ddm_wrapper, \n",
    "               args=(sigma, rts_sim, corrects_sim),\n",
    "               method='SLSQP', x0=x0, bounds=[(0.3,1.5),(0.5,0.5)])\n",
    "ll_B = -res_B.fun # get log likelihood\n",
    "bic.append(-2*ll_B+1*np.log(N_data))\n",
    "\n",
    "# Fit data to restricted mu model\n",
    "res_Null = minimize(get_nll_ddm_wrapper, \n",
    "               args=(sigma, rts_sim, corrects_sim),\n",
    "               method='SLSQP', x0=x0, bounds=[(0,0),(0.5,3)])\n",
    "ll_Null = -res_Null.fun # get log likelihood\n",
    "bic.append(-2*ll_Null+1*np.log(N_data))\n",
    "\n",
    "print('BIC for models: ')\n",
    "print('Full Model BIC: ' + str(-2*ll_full+2*np.log(N_data)) )\n",
    "print('Restricted B Model BIC: ' + str(-2*ll_B+1*np.log(N_data)) )\n",
    "print('Restricted Mu Model BIC: ' + str(-2*ll_Null+1*np.log(N_data)) )\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(3),bic-min(bic))\n",
    "plt.xticks(range(3), ('Full', 'Restricted B', 'Restricted Mu'))\n",
    "plt.ylabel('BIC difference vs. winning model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-11T20:30:58.156378Z",
     "start_time": "2018-06-11T20:30:57.851061Z"
    }
   },
   "source": [
    "***Expected output***\n",
    "\n",
    "![](./figures/expected_ex7_1.png)\n",
    "\n",
    "![](./figures/expected_ex7_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
