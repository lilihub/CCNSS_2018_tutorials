{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCNSS 2018: Module 2 Tutorial 4\n",
    "# Computational psychiatry assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please execute the cell below to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:04.393377Z",
     "start_time": "2018-06-15T23:35:01.793641Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-158639529832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbeta\u001b[0m       \u001b[0;31m# import beta distribution for BetaBinomial model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfig_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import  pandas  as  pd             # import pandas\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "import time                        # import time function to time minimize\n",
    "from scipy.optimize import minimize #import optimization functions\n",
    "from scipy.stats import beta       # import beta distribution for BetaBinomial model\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows to call the function 'hide_toggle' that shows/hides solutions for each exercise\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Show/hide Solution below'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' '\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T11:35:01.939044Z",
     "start_time": "2018-06-12T11:35:01.932568Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "In this notebook we'll use our previous knowledge and skills at analysing data and fitting probabilistic generative models of behaviour.\n",
    "We will analyze, plot, and fit data to a synthetic dataset of Healthy controls (CTR) and Patients with Major Depressive Disorder (MDD).\n",
    "\n",
    "- Extract and clean-up data\n",
    "- Analyze and plot behavioural data\n",
    "- Fit BetaBinomial model to dataset\n",
    "- Plot parameters recovered for each group\n",
    "- Develop modifications of the BetaBinomial model and constrained nested BetaBinomial models\n",
    "- Do model comparison and model selection with different models on each dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Computational psychiatry is a young field in expansion at the intersection between computational neuroscience and psychiatry. This discipline builds on the initial efforts in the 80’s using connectionist models, but has also evolved to get closer to the physiological substrate and to more testable predictions. Although psychiatric disorders are characterised essentially by their high-level symptoms, following Marr’s principles, computational models can help formalise symptoms and hypotheses to bridge the gap between neurobiology and psychiatry. \n",
    "\n",
    "That is, computational models are able to provide a normative framework to explicitly define and rigorously test competing hypotheses of mental disorders, while providing a link between different levels of descriptions.\n",
    "\n",
    "For example, modelling for psychiatry can be done using a `deductive` or `abductive` approach, each of which can lead to different predictions for psychiatry. \n",
    "\n",
    "Using a `deductive approach` scientists can start from the premise of known neurobiological deficits observed in mental disorders, and implement these deficits in a computational model. The performance of the model is then compared to this of patients. If the model can account for the performance observed in patients, it provides a mechanistic account to bridge biological abnormalities to behaviour or neural activity.\n",
    "\n",
    "Using the `abductive approach` on the other hand, scientists can start from the premise of a model of normal behaviour and alter the model in multiple ways to generate distinct novel hypotheses of brain dysfunction. All these models are then fitted to the behaviour of patients to find which hypothesis (different models) accounts best for their performance and/or deficits. The winning hypothesis can then be refined in an attempt to explain the deficits at lower levels of description, or used to devise new experimental tests that will precisely assay the dysfunction suggested by the winning hypothesis.\n",
    "\n",
    "In this tutorial we will use an `abductive approach`. That is, we will use a model of correct (healthy) behaviour to solve our task, and fit the model to the data of patients. We will then alter the model to see if it can better explain patient behaviour and/or deficits. \n",
    "\n",
    "Alternatively, if we find that patients and controls use the same model to solve the task, we will look at the range of parameters extracted for each group and see if patients and controls differ on some parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:04:18.921132Z",
     "start_time": "2018-06-12T13:04:18.914893Z"
    }
   },
   "source": [
    "***EXERCISE 1***\n",
    "\n",
    "![](./figures/Optimism_task.png)\n",
    "\n",
    "We collected a new dataset from the optimism task (as seen above and descibed in Tutorial 3).\n",
    "We recruited 100 participants, 50 Healthy controls, and 50 patients with Major Depressive Disorder.\n",
    "\n",
    "The data is contained in the data file `optimism_comp_psychiatry.csv`. The first 50 subjects are patients, the last 50 subjects are controls.\n",
    "\n",
    "Load and clean-up the data.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Read the data from file 'optimism_comp_psychiatry.csv'\n",
    "* Each line is one decision trial, the columnns encode\n",
    "    - the subject number\n",
    "    - the true expected value of the fractal stimulus\n",
    "    - the expected value of the target stimulus\n",
    "    - the decision \n",
    "    - the reaction time\n",
    "* decision / choice is encoded as: 1 = chooses fractal stimulus, 2 = chooses target stimulus\n",
    "* replace numbers '1' and '2' for 'fractal' and 'target' to 1 for fractal and 0 for target\n",
    "* Make sure the field 'choice' is a number\n",
    "* print the first 5 rows of the data (hint: look up function 'head()' in pandas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3325336075773382069() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3325336075773382069()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:04.443851Z",
     "start_time": "2018-06-15T23:35:04.395582Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "df = pd.read_csv('data/optimism_comp_psychiatry.csv',delimiter=',')\n",
    "\n",
    "df.replace({'choice': {1.: '1', 2.: '0'},\n",
    "                 }, inplace=True)\n",
    "\n",
    "df['choice'] = df['choice'].astype(np.float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:05:57.043554Z",
     "start_time": "2018-06-12T13:05:57.034495Z"
    }
   },
   "source": [
    "***EXERCISE 2***\n",
    "\n",
    "Calculate and plot the psychometric function for all controls (Participants with subject_id 50 to 100) \n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Loop over participants, and load their data sequentially\n",
    "    * Calculate the psychometric curve for a given participant data (hint: the data has the same form as in tutorial 3, so you may reuse your previous functions)\n",
    "    * Calculate the sigmoid fit to the participant's data (hint: use the sigmoid function defined in Tutorial 3, you may want to use `scipy.optimize.curve_fit`, but this time fit the sigmoid curve to the raw participant data instead of the bins for the pre-computed psychometric curve)\n",
    "* Note how subjects can have different psychometric function that are shifted either left or right; What do you think this means? (hint: think of it in terms of an optimism/pessimism bias)\n",
    "* Which participants appear more 'optimistic' ?\n",
    "* Display 2 subplots, one with the true psychometric curve for all subjects, another with the fitted sigmoids for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11602498617786843311() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11602498617786843311()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:07.215299Z",
     "start_time": "2018-06-15T23:35:04.446150Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "def sigmoid(x, x0, k):\n",
    "    y = 1 / (1 + np.exp(-k*(x-x0)))\n",
    "    return y\n",
    "\n",
    "params_sig=np.full((100,2),np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,7),sharey=True)\n",
    "\n",
    "# Create column 'diff_frac2targ' which computes difference in expected value between fractal and target\n",
    "df['diff_frac2targ']=df['bin_coef']-df['target_coef']\n",
    "\n",
    "# Define the bins for plotting psychometric curve\n",
    "freq_bins= np.array([-1.01, -0.5, 0, 0.5, 1.01])\n",
    "\n",
    "#Create 'binned' column and bin each trial as belonging to either bin defined in freq_bins\n",
    "df['binned']= pd.cut(df['diff_frac2targ'], bins=freq_bins)\n",
    "\n",
    "#Select data for subject 1 only\n",
    "for i in range(50,100):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i+1)]\n",
    "\n",
    "    #Groupby data for subject i\n",
    "    choice_groupby_binned = df_subj['choice'].groupby(df_subj['binned'])\n",
    "    \n",
    "    #Print sigmoid fit to the data\n",
    "    my_vals=np.array(choice_groupby_binned.mean())\n",
    "    my_vals=my_vals[~np.isnan(my_vals)]\n",
    "    popt, pcov = curve_fit(sigmoid, df_subj['diff_frac2targ'], df_subj['choice'])\n",
    "    params_sig[i]=popt;\n",
    "    ax[1].plot(df_subj['diff_frac2targ'], df_subj['choice'], 'ob',  alpha=0.01, label='data')\n",
    "    ax[1].plot(np.linspace(-1, 1, 100),sigmoid(np.linspace(-1, 1, 100), *popt),'-b',lw=2,alpha=0.1)\n",
    "    ax[0].plot(range(len(my_vals)), my_vals, '-b', lw=2, alpha=0.1, label='data')\n",
    "    ax[0].set_xticks(range(len(my_vals)))\n",
    "    ax[0].set_xticklabels(['[-1,-0.5]' ,'[-0.5,0]' ,'[0,0.5]' ,'[0.5,1]'])\n",
    "    \n",
    "ax[0].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[0].set_xlabel('Binned : Difference in reward probability (Fractal-Target)')\n",
    "ax[0].set_title('Psychometric function for: Controls')\n",
    "ax[1].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[1].set_xlabel('True Difference in reward probability (Fractal-Target)')\n",
    "ax[1].set_title('Fitted Psychometric function for: Controls')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 3***\n",
    "\n",
    "Calculate and plot the psychometric function for all patients & controls on the same plot\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Loop over participants, and load their data sequentially\n",
    "    * Use your previous function which calculates the psychometric curve for a given participant data.\n",
    "    * Plot the participant fitted sigmoidal response with an alpha=0.05\n",
    "* Note how subjects can have different psychometric function that are shifted either left/right or up/down; What do you think this means? (hint: think of it in terms of a bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6137171966851451180() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6137171966851451180()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:11.421090Z",
     "start_time": "2018-06-15T23:35:07.235407Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "params_sig=np.full((100,2),np.nan)\n",
    "psychometric_values=np.full((100,4),np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,7),sharey=True)\n",
    "\n",
    "# Create column 'diff_frac2targ' which computes difference in expected value between fractal and target\n",
    "df['diff_frac2targ']=df['bin_coef']-df['target_coef']\n",
    "\n",
    "# Define the bins for plotting psychometric curve\n",
    "freq_bins= np.array([-1.01, -0.5, 0, 0.5, 1.01])\n",
    "\n",
    "#Create 'binned' column and bin each trial as belonging to either bin defined in freq_bins\n",
    "df['binned']= pd.cut(df['diff_frac2targ'], bins=freq_bins)\n",
    "\n",
    "#Select data for subject 1 only\n",
    "for i in range(100):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i+1)]\n",
    "\n",
    "    #Groupby data for subject i\n",
    "    choice_groupby_binned = df_subj['choice'].groupby(df_subj['binned'])\n",
    "    \n",
    "    #Print sigmoid fit to the data\n",
    "    my_vals=np.array(choice_groupby_binned.mean())\n",
    "    psychometric_values[i,:]=my_vals;\n",
    "    my_vals=my_vals[~np.isnan(my_vals)]\n",
    "    popt, pcov = curve_fit(sigmoid, df_subj['diff_frac2targ'], df_subj['choice'])\n",
    "    params_sig[i]=popt;\n",
    "    if i < 50:\n",
    "        ax[0].plot(range(len(my_vals)), my_vals, '-r', lw=2, alpha=0.1, label='Patients')\n",
    "        ax[1].plot(df_subj['diff_frac2targ'], df_subj['choice'], 'or',  alpha=0.01, label='data')\n",
    "        ax[1].plot(np.linspace(-1, 1, 100),sigmoid(np.linspace(-1, 1, 100), *popt),'-r',lw=2,alpha=0.1)\n",
    "    else:\n",
    "        ax[0].plot(range(len(my_vals)), my_vals, '-b', lw=2, alpha=0.1, label='Controls')\n",
    "        ax[1].plot(df_subj['diff_frac2targ'], df_subj['choice'], 'ob',  alpha=0.01, label='data')\n",
    "        ax[1].plot(np.linspace(-1, 1, 100),sigmoid(np.linspace(-1, 1, 100), *popt),'-b',lw=2,alpha=0.1)\n",
    "    ax[0].set_xticks(range(len(my_vals)))\n",
    "    ax[0].set_xticklabels(['[-1,-0.5]' ,'[-0.5,0]' ,'[0,0.5]' ,'[0.5,1]'])\n",
    "    \n",
    "ax[0].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[0].set_xlabel('Binned : Difference in reward probability (Fractal-Target)')\n",
    "ax[0].set_title('Psychometric function for: \\n Controls(Blue) and Patients (Red)')\n",
    "ax[1].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[1].set_xlabel('True Difference in reward probability (Fractal-Target)')\n",
    "ax[1].set_title('Fitted Psychometric function for: \\n Controls(Blue) and Patients (Red)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:07:59.350916Z",
     "start_time": "2018-06-12T13:07:59.345075Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 4***\n",
    "\n",
    "We have plotted estimated sigmoidal fit and raw behaviour of participants, and it looks as if there may be some some shift of the psychometric curve between Patients (red) and Controls (blue).\n",
    "\n",
    "Let's try and quantify this by summarizing the data per groups.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Plot the mean and standard deviation of the psychometric curve at each bins, for each group using errorbars.\n",
    "* The mean+- standard deviation may hide valuable information (i.e. non-normally distributed data, skewness, kurtosis, etc). \n",
    "Let's reproduce the same graph but this time using violin plots stacked onto one another. This will give us information regarding the shape and skewness in the data (violin plot). (hint: you may want to use the function  `violinplot` from `matplotlib`. Alternatively you may use `seaborn`)\n",
    "* Plot the smoothed histogram (also known as Kernel Density Estimation -- KDE) of the parameters extracted from the sigmoid fits to the data. Plot one KDE per group and parameter. (hint: you may want to use the function `kdeplot` from `seaborn`)\n",
    "    * Considering the amount of overlap between the two groups over the parameter space, do you believe that they are indeed two different populations? \n",
    "    * What do you think it means, if one parameter is different but not the other?\n",
    "    * (optional) Run statistics on your parameters and report them (hint: you may want to use independent t-tests, assuming the data is normally distributed)\n",
    "* (optional) Run a two-way repeated-measure ANOVA on the psychometric curves (Report the Group, Bin, and Group x Bin interaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17052483510441772751() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17052483510441772751()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:12.411478Z",
     "start_time": "2018-06-15T23:35:11.422972Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "fig, ax = plt.subplots(2,2,figsize=(20,12))\n",
    "\n",
    "ax[0,0].errorbar(range(len(my_vals)), np.mean(psychometric_values[0:49,:],axis=0), yerr=np.std(psychometric_values[0:49,:],axis=0),marker='o',lw=2,alpha=0.6,label='Patients')\n",
    "ax[0,0].errorbar(range(len(my_vals)), np.mean(psychometric_values[50:100,:],axis=0), yerr=np.std(psychometric_values[50:100,:],axis=0),marker='o',lw=2,alpha=0.6,label='Controls')\n",
    "ax[0,0].legend(loc='best', frameon=False)\n",
    "ax[0,0].set_xticks(range(len(my_vals)))\n",
    "ax[0,0].set_xticklabels(['[-1,-0.5]' ,'[-0.5,0]' ,'[0,0.5]' ,'[0.5,1]'])\n",
    "ax[0,0].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[0,0].set_xlabel('Binned : Difference in reward probability (Fractal-Target)')\n",
    "ax[0,0].set_title('Mean Psychometric function for: \\n Controls(Blue) and Patients (Red)')\n",
    "\n",
    "ax[0,1].violinplot(psychometric_values[0:49,:],showmeans=False,showmedians=True,showextrema=False)\n",
    "ax[0,1].plot(np.array([1, 2, 3, 4]),np.mean(psychometric_values[0:49,:],axis=0),'--r',marker='o',lw=2,alpha=0.3,label='Patients')\n",
    "ax[0,1].violinplot(psychometric_values[50:100,:],showmeans=False,showmedians=True,showextrema=False)\n",
    "ax[0,1].plot(np.array([1, 2, 3, 4]),np.mean(psychometric_values[50:100,:],axis=0),'.-b',marker='o',lw=2,alpha=0.3,label='Controls')\n",
    "ax[0,1].legend(loc='best', frameon=False)\n",
    "ax[0,1].set_xticks(np.array([1, 2, 3, 4]))\n",
    "ax[0,1].set_xticklabels(['[-1,-0.5]' ,'[-0.5,0]' ,'[0,0.5]' ,'[0.5,1]'])\n",
    "ax[0,1].set_ylabel('Probability of choosing `fractal`')\n",
    "ax[0,1].set_xlabel('Binned : Difference in reward probability (Fractal-Target)')\n",
    "ax[0,1].set_title('Mean, Mode & distribution of Psychometric function for: \\n Controls(Blue) and Patients (Red)')\n",
    "\n",
    "params_sig0=params_sig[params_sig[:,0]<0.75,0]; #remove incorrectly estimated parameters\n",
    "params_sig1=params_sig[params_sig[:,1]<10,1];   #remove incorrectly estimated parameters\n",
    "\n",
    "sns.kdeplot(params_sig0[0:49],shade=True, color='red', ax=ax[1,0], label='KDE Patient')\n",
    "sns.kdeplot(params_sig0[50:99],shade=True, color='blue', ax=ax[1,0], label='KDE Control')\n",
    "ax[1,0].set_ylabel('PDF estimated from data')\n",
    "ax[1,0].set_xlabel('`x0`: Sigmoid bias (mid-point)')\n",
    "ax[1,0].set_title('Kernel Density Estimation of Sigmoid Parameter `x0`')\n",
    "\n",
    "#ax[1,0].set_xlim([-0.75, 0.75])\n",
    "sns.kdeplot(params_sig1[0:49],shade=True, color='red', ax=ax[1,1], label='KDE Patient')\n",
    "sns.kdeplot(params_sig1[50:99],shade=True, color='blue', ax=ax[1,1], label='KDE Control')\n",
    "ax[1,1].set_ylabel('PDF estimated from data')\n",
    "ax[1,1].set_xlabel('`k`: Sigmoid steepness (curvature)')\n",
    "ax[1,1].set_title('Kernel Density Estimation of Sigmoid Parameter `k`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 5***\n",
    "\n",
    "Depressive Realism or Healthy optimism?\n",
    "\n",
    "Patients with Major Depression often tend to have lower scores on optimism self-reports than healthy controls. \n",
    "We could think of this as meaning that they would be more 'pessimistic' than healthy controls. \n",
    "However, it turns out that, when you ask MDD patients and controls to report the probability of something good or bad happening to them, patients tend to report accurate probabilities more often, while healthy controls overestimate the probability of something good happening to them (say: winning the lottery) and underestimate the probability of something bad happening to them (e.g.: getting robbed , or getting cancer). \n",
    "This is sometimes known as the 'optimism bias' in healthy controls, and the 'depressive realism' in patients.\n",
    "\n",
    "In our experiment, we also asked participants to fill in a questionnaire measuring their optimism levels (found in data file: optimism_questionnaire.csv).\n",
    "\n",
    "Lower scores in the scale suggests that a participants are more pessimistic, while high scores reflects optimism.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Load the questionnaire scores\n",
    "* Plot a Kernel density overlayed onto the histogram of questionnaire scores for each group (Patients in red, Controls in blue). hint: you may want to use the function `distplot` from `seaborn`\n",
    "* What do you observe?\n",
    "* Can you see a significant difference between the two groups in terms of optimism/pessimism score?\n",
    "    * Does this conform to what we would expect, considering what we know of optimism/pessimism in patients and controls?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17257927787329527520() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17257927787329527520()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:12.732792Z",
     "start_time": "2018-06-15T23:35:12.413910Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "df_optim = pd.read_csv('data/optimism_questionnaire.csv',delimiter=',')\n",
    "\n",
    "df_optim['optimism_score'] = df_optim['optimism_score'].astype(np.int)\n",
    "optimism = np.array(df_optim['optimism_score'])\n",
    "\n",
    "ax=sns.distplot(optimism[0:49], bins=10,color='red', label='KDE Patient')\n",
    "ax=sns.distplot(optimism[50:99], bins=10,color='blue', label='KDE Control')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "ax.set_ylabel('Probability Density')\n",
    "ax.set_xlabel('Optimism questionnaire score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:10:56.348633Z",
     "start_time": "2018-06-12T13:10:56.340794Z"
    }
   },
   "source": [
    "# Application: Fitting the BetaBinomial model to the data\n",
    "\n",
    "***EXERCISE 6***\n",
    "\n",
    "Now that we have plotted the raw behavioural data for both groups. We can try to fit the BetaBinomial model from last class to our new dataset.\n",
    "    \n",
    "***Suggestions***\n",
    "\n",
    "* Import your own `Beta Binomial` model based on the work from the last tutorial (copy the functions `get_softmax`, `get_mean_BetaBinomial`, `get_negll_mean_BetaBinom`)\n",
    "* Write a wrapper for the function `get_negll_mean_BetaBinom` so that you have all parameters in an array, and can load different datasets\n",
    "* Load each subject sequentially and fit the model to each subjects \n",
    "    * Use the following: `initial_guess=[1,1,0.1]\n",
    "    * Use the following bounds: `bounds=[(0.01,6),(0.01,6),(0.01,0.8)]`\n",
    "    * Store the parameters $a$, $b$, $tau$, and the negative log_likelihoods for each subject\n",
    "    * Print the parameters $a$, $b$, $tau$, `log_likelihoods` and time taken to converge for subject 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_11123595079752057258() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_11123595079752057258()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:12.748687Z",
     "start_time": "2018-06-15T23:35:12.736118Z"
    },
    "code_folding": [
     0,
     2,
     19,
     41
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "def get_softmax(x,tau):\n",
    "    \"\"\"\n",
    "    Function that implements the softmax link function\n",
    "    ----------\n",
    "    x: array of 2 values \n",
    "        Success rates Ci for each option 1 & 2 (in our case success probability of Fractal vs. Target)\n",
    "    tau: integer > 0 \n",
    "        Temperature parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood: \n",
    "        probability of chosing each value of x respectively, as a function of tau, and values of x\n",
    "    \"\"\"\n",
    "    \n",
    "    return (np.exp( (x - np.max(x)) / tau) / np.sum(np.exp( (x - np.max(x)) / tau), axis=0))\n",
    "\n",
    "def get_mean_BetaBinomial(a, b, n, N):\n",
    "    \"\"\"\n",
    "    Function that implements the BetaBinomial conjugate model and returns the mean of the posterior\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: integer > 0\n",
    "        Number of presentations for fractal\n",
    "    n: integer > 0 & =< N\n",
    "        Number of rewarded presentations of the fractal\n",
    "    c: float > [0..1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    negative log-likelihood: \n",
    "        probability of occurence given the parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    c = ( n + a ) / (N + a + b)\n",
    "    \n",
    "    return c\n",
    "\n",
    "def get_negll_mean_BetaBinom(a,b,tau, data):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the BetaBinomial model with softmax link function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 3: 1st entry is a (shape of Beta prior), 2nd is b \n",
    "        (2nd shape parameter of Beta prior), 3rd is tau (temperature parameter)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    data : array_like of decision trials.\n",
    "        contains n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "    \n",
    "    l=list()\n",
    "    \n",
    "    for i_trial in range(len(data)):\n",
    "        n=data[i_trial,1]\n",
    "        N=data[i_trial,2]\n",
    "        target=data[i_trial,4]\n",
    "        c_hat= get_mean_BetaBinomial(a, b, n, N)\n",
    "        choice_likelihoods=get_softmax([target,c_hat],tau)+1e-100     #target always 1st elem (0), and fractal 2nd elem (1), so that it matches df['choice']=0 or 1 for target/fractal respectively  \n",
    "        l.append(choice_likelihoods[int(data[i_trial,5])])        \n",
    "        \n",
    "    return -np.sum(np.log(l))\n",
    "\n",
    "get_nll_mean_BetaBinomial_wrapper = lambda parameters, data: get_negll_mean_BetaBinom(parameters[0], parameters[1], parameters[2], data)\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:30.078116Z",
     "start_time": "2018-06-15T23:35:12.751880Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "# Store parameters found\n",
    "est_a, est_b, est_tau, ll_mean= list(), list(), list(), list()\n",
    "\n",
    "# Optimization (find parameters that minimize nll)\n",
    "initial_guess = [1,1,0.1]\n",
    "bounds = [(0.01,6),(0.01,6),(0.01,0.8)] # Optimization bounds\n",
    "\n",
    "#Select data 1 subject at a time\n",
    "for i_subj in range(len(df['subject_id'].unique())):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i_subj+1)]\n",
    "    np_subj = np.array(df_subj)\n",
    "    \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mean_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=initial_guess, bounds=bounds)\n",
    "    ll_mean.append(-res.fun)\n",
    "    t_end_optim = time.time()\n",
    "    est_a.append(res.x[0])\n",
    "    est_b.append(res.x[1])\n",
    "    est_tau.append(res.x[2])\n",
    "    if i_subj<5:\n",
    "        print('Participant :'+str(i_subj+1))\n",
    "        print('Estimated a:'+str(round(est_a[i_subj],2))+' , b:'+str(round(est_b[i_subj],2))+' , tau:'+str(round(est_tau[i_subj],2)) )\n",
    "        print('LL :'+str(round(ll_mean[i_subj],5))+' , time taken:'+str(round(t_end_optim-t_start_optim,2))+' seconds')\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T22:25:03.521427Z",
     "start_time": "2018-06-15T22:25:03.514334Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:24:27.351008Z",
     "start_time": "2018-06-12T13:24:27.343072Z"
    }
   },
   "source": [
    "***EXERCISE 7***\n",
    "\n",
    "Plot the parameters recovered in each group using violin plots and box plots\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Using distribution plots `distplot`, display the parameters recovered, per group for:\n",
    "    * $a$\n",
    "    * $b$\n",
    "    * Mean of the prior. (hint: the mean of a Beta distribution is $\\left(\\frac{a}{a + b}\\right)$)\n",
    "    * $tau$\n",
    "* Compare the mean of the prior to the self-report measures of optimism. What do you find? What do you think this means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9246504389748776991() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9246504389748776991()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:31.230015Z",
     "start_time": "2018-06-15T23:35:30.080626Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(15,7))\n",
    "\n",
    "sns.distplot(est_a[0:49], bins=10,color='red', label='KDE Patient', ax=ax[0,0])\n",
    "sns.distplot(est_a[50:99], bins=10,color='blue', label='KDE Control', ax=ax[0,0])\n",
    "ax[0,0].legend(loc='best', frameon=False)\n",
    "ax[0,0].set_ylabel('Probability Density')\n",
    "ax[0,0].set_xlabel('Beta prior, parameter: `a`')\n",
    "\n",
    "sns.distplot(est_b[0:49], bins=10,color='red', label='KDE Patient', ax=ax[0,1])\n",
    "sns.distplot(est_b[50:99], bins=10,color='blue', label='KDE Control', ax=ax[0,1])\n",
    "ax[0,1].legend(loc='best', frameon=False)\n",
    "ax[0,1].set_ylabel('Probability Density')\n",
    "ax[0,1].set_xlabel('Beta prior, parameter: `b`')\n",
    "\n",
    "prior_mean_patients=(np.array(est_a[0:49]))/(np.array(est_a[0:49])+np.array(est_b[0:49]))\n",
    "prior_mean_controls=(np.array(est_a[50:99]))/(np.array(est_a[50:99])+np.array(est_b[50:99]))\n",
    "\n",
    "sns.distplot(prior_mean_patients, bins=10,color='red', label='KDE Patient', ax=ax[1,0])\n",
    "sns.distplot(prior_mean_controls, bins=10,color='blue', label='KDE Control', ax=ax[1,0])\n",
    "ax[1,0].legend(loc='best', frameon=False)\n",
    "ax[1,0].set_ylabel('Probability Density')\n",
    "ax[1,0].set_xlabel('Beta prior, mean: `a/(a+b)`')\n",
    "\n",
    "sns.distplot(est_tau[0:49], bins=10,color='red', label='KDE Patient', ax=ax[1,1])\n",
    "sns.distplot(est_tau[50:99], bins=10,color='blue', label='KDE Control', ax=ax[1,1])\n",
    "ax[1,1].legend(loc='best', frameon=False)\n",
    "ax[1,1].set_ylabel('Probability Density')\n",
    "ax[1,1].set_xlabel('Temperature parameter: `tau`')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(optimism[0:49],prior_mean_patients,'or',alpha=0.4)\n",
    "plt.plot(optimism[50:99],prior_mean_controls,'ob',alpha=0.4)\n",
    "plt.plot(np.linspace(5,25,100), 0.045*np.linspace(5,25,100)-0.15, '--k')\n",
    "plt.ylabel('Mean of Prior: `a/(a+b)`');\n",
    "plt.xlabel('Optimism Score (Higher = Optimistic)');\n",
    "plt.legend(loc='best', frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:34:21.322268Z",
     "start_time": "2018-06-12T13:34:21.314267Z"
    }
   },
   "source": [
    "***EXERCISE 8***\n",
    "\n",
    "Let's try the `abductive approach` and modify the correct model of behaviour (i.e. the mean_BetaBinomial model).\n",
    "We'll then be able to test these model against behaviour to find out whether our participants appear to be using the strategy (i.e. 'model') we think they're actually using.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Alter the BetaBinomial model so that instead of taking the mean of the posterior for our behavioural outcomes, we assume participant chose the mode of the posterior. \n",
    "The mode of the posterior is defined by : $\\left(\\frac{n_i + \\alpha - 1}{N_i + \\alpha + \\beta - 2}\\right)$\n",
    "* Alter the BetaBinomial model so that instead of taking the mean of the posterior for our behavioural outcomes, we assume participant chose the median of the posterior. \n",
    "The mode of the posterior is defined by : $\\left(\\frac{n_i + \\alpha - 1/3}{N_i + \\alpha + \\beta - 1/3}\\right)$\n",
    "* Using your functions, calculate and print the likelihood for subject 1, with parameters $a=5$, $b=2$, $tau=0.1$ on:\n",
    "    * median_Beta_Binomial\n",
    "    * mode_Beta_Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13734070487707938957() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13734070487707938957()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:31.256286Z",
     "start_time": "2018-06-15T23:35:31.233174Z"
    },
    "code_folding": [
     0,
     22,
     44,
     76
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "def get_mode_BetaBinomial(a, b, n, N):\n",
    "    \"\"\"\n",
    "    Function that implements the BetaBinomial conjugate model and returns the mean of the posterior\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: integer > 0\n",
    "        Number of presentations for fractal\n",
    "    n: integer > 0 & =< N\n",
    "        Number of rewarded presentations of the fractal\n",
    "    c: float > [0..1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    negative log-likelihood: \n",
    "        probability of occurence given the parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    c = ( n + a -1) / (N + a + b -2)\n",
    "    \n",
    "    return c\n",
    "\n",
    "def get_median_BetaBinomial(a, b, n, N):\n",
    "    \"\"\"\n",
    "    Function that implements the BetaBinomial conjugate model and returns the mean of the posterior\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: integer > 0\n",
    "        Number of presentations for fractal\n",
    "    n: integer > 0 & =< N\n",
    "        Number of rewarded presentations of the fractal\n",
    "    c: float > [0..1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    negative log-likelihood: \n",
    "        probability of occurence given the parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    c = ( n + a -(1/3)) / (N + a + b -(1/3))\n",
    "    \n",
    "    return c\n",
    "\n",
    "def get_negll_mode_BetaBinom(a,b,tau, data):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the BetaBinomial model with softmax link function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 3: 1st entry is a (shape of Beta prior), 2nd is b \n",
    "        (2nd shape parameter of Beta prior), 3rd is tau (temperature parameter)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    data : array_like of decision trials.\n",
    "        contains n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "    \n",
    "    l=list()\n",
    "    \n",
    "    for i_trial in range(len(data)):\n",
    "        n=data[i_trial,1]\n",
    "        N=data[i_trial,2]\n",
    "        target=data[i_trial,4]\n",
    "        c_hat= get_mode_BetaBinomial(a, b, n, N)\n",
    "        choice_likelihoods=get_softmax([target,c_hat],tau)+1e-100     #target always 1st elem (0), and fractal 2nd elem (1), so that it matches df['choice']=0 or 1 for target/fractal respectively  \n",
    "        l.append(choice_likelihoods[int(data[i_trial,5])])        \n",
    "        \n",
    "    return -np.sum(np.log(l))\n",
    "\n",
    "def get_negll_median_BetaBinom(a,b,tau, data):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the BetaBinomial model with softmax link function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 3: 1st entry is a (shape of Beta prior), 2nd is b \n",
    "        (2nd shape parameter of Beta prior), 3rd is tau (temperature parameter)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    data : array_like of decision trials.\n",
    "        contains n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "    \n",
    "    l=list()\n",
    "    \n",
    "    for i_trial in range(len(data)):\n",
    "        n=data[i_trial,1]\n",
    "        N=data[i_trial,2]\n",
    "        target=data[i_trial,4]\n",
    "        c_hat= get_median_BetaBinomial(a, b, n, N)\n",
    "        choice_likelihoods=get_softmax([target,c_hat],tau)+1e-100     #target always 1st elem (0), and fractal 2nd elem (1), so that it matches df['choice']=0 or 1 for target/fractal respectively  \n",
    "        l.append(choice_likelihoods[int(data[i_trial,5])])        \n",
    "        \n",
    "    return -np.sum(np.log(l))\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_14951505745154189961() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_14951505745154189961()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:35:31.317095Z",
     "start_time": "2018-06-15T23:35:31.283050Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "df_subj = df.loc[(df['subject_id']==i_subj+1)]\n",
    "np_subj = np.array(df_subj)\n",
    "\n",
    "print('Participant :'+str(1)+' , using a: 5 , b: 2 , tau: 0.1' )\n",
    "print('LL model median_BetaBinom: '+str(-get_negll_median_BetaBinom(5,2,0.1, np_subj)))\n",
    "print('LL model mode_BetaBinom: '+str(-get_negll_mode_BetaBinom(5,2,0.1, np_subj)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:34:42.148538Z",
     "start_time": "2018-06-12T13:34:42.143823Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:36:53.949429Z",
     "start_time": "2018-06-12T13:36:53.940001Z"
    }
   },
   "source": [
    "***EXERCISE 9***\n",
    "\n",
    "Fit the 3 different models of behaviour to the data of controls and patients, and use boundaries to create constrained nested models.\n",
    "\n",
    "Do model comparison using the BIC on each group separately, and report which model wins overall and for each group.\n",
    "\n",
    "You may want to use the following table to compare the evidence for each model and decide which model 'wins':\n",
    "\n",
    "![](./figures/KassRaftery_BayesFactor.png)\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Fit a Null model using the BetaBinomial_mean to the controls and patient dataset (hint: you may want to restrict the range of the parameter values using the bounds of the minimization function)\n",
    "* Fit a No_Bias (no prior) model using the BetaBinomial_mean to the controls and patient dataset (hint: instead of changing the model, you may want to restrict the range of the prior parameter values, so that the prior is completely uniform and un-informative)\n",
    "* Fit the model BetaBinomial_mode to the controls and patient dataset\n",
    "* Fit the model BetaBinomial_median to the controls and patient dataset\n",
    "* Calculate the BIC per model, per subject\n",
    "* Report and plot the BIC for each model, for all subjects combined, then per group. \n",
    "    * What does this suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2851797320949542498() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2851797320949542498()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:36:28.351898Z",
     "start_time": "2018-06-15T23:35:31.319766Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "get_nll_mode_BetaBinomial_wrapper = lambda parameters, data: get_negll_mode_BetaBinom(parameters[0], parameters[1], parameters[2], data)\n",
    "get_nll_median_BetaBinomial_wrapper = lambda parameters, data: get_negll_median_BetaBinom(parameters[0], parameters[1], parameters[2], data)\n",
    "\n",
    "# Store parameters found\n",
    "ll_mode, ll_median , ll_null, ll_nobias= list(), list(), list(), list()\n",
    "bic = np.full((100,5),np.nan)\n",
    "N_trials = 60\n",
    "\n",
    "# Optimization (find parameters that minimize nll)\n",
    "initial_guess = [1,1,0.1]\n",
    "bounds = [(0.01,6),(0.01,6),(0.01,0.8)] # Optimization bounds\n",
    "\n",
    "#Select data 1 subject at a time\n",
    "for i_subj in range(len(df['subject_id'].unique())):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i_subj+1)]\n",
    "    np_subj = np.array(df_subj)\n",
    "       \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mean_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=[1,1,100], bounds=[(1,1),(1,1),(100,100)])\n",
    "    ll_null.append(-res.fun)\n",
    "    bic[i_subj,0]=-2*(-res.fun)+0*np.log(N_trials)\n",
    "    \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mean_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=[1,1,0.15], bounds=[(1,1),(1,1),(0.01,0.8)])\n",
    "    ll_nobias.append(-res.fun)\n",
    "    bic[i_subj,1]=-2*(-res.fun)+1*np.log(N_trials)\n",
    "        \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mean_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=initial_guess, bounds=bounds)\n",
    "    ll_mean.append(-res.fun)\n",
    "    bic[i_subj,2]=-2*(-res.fun)+3*np.log(N_trials)\n",
    "    \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mode_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=initial_guess, bounds=bounds)\n",
    "    ll_mode.append(-res.fun)\n",
    "    bic[i_subj,3]=-2*(-res.fun)+3*np.log(N_trials)\n",
    "    \n",
    "    res = minimize(get_nll_median_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=initial_guess, bounds=bounds)\n",
    "    ll_median.append(-res.fun)\n",
    "    bic[i_subj,4]=-2*(-res.fun)+3*np.log(N_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9979395983541781781() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9979395983541781781()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:36:29.502173Z",
     "start_time": "2018-06-15T23:36:28.354116Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(20,7),sharey=True)\n",
    "\n",
    "ax[0].bar(range(5),np.sum(bic,axis=0)-np.min(np.sum(bic,axis=0)),color='black')\n",
    "ax[0].set_xticks(range(5))\n",
    "ax[0].set_xticklabels(('Null', 'No Bias', 'Beta Mean', 'Beta Mode', 'Beta Median'))\n",
    "ax[0].set_ylabel('BIC difference vs. winning model')\n",
    "ax[0].set_title('Model comparison accross all subjects')\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].bar(range(5),np.sum(bic[50:100,:],axis=0)-np.min(np.sum(bic[50:100,:],axis=0)),color='blue')\n",
    "ax[1].set_xticks(range(5))\n",
    "ax[1].set_xticklabels(('Null', 'No Bias', 'Beta Mean', 'Beta Mode', 'Beta Median', 'Null', 'No Bias'))\n",
    "ax[1].set_ylabel('BIC difference vs. winning model')\n",
    "ax[1].set_title('Model comparison for Controls')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[2].bar(range(5),np.sum(bic[0:49,:],axis=0)-np.min(np.sum(bic[0:49,:],axis=0)),color='red')\n",
    "ax[2].set_xticks(range(5))\n",
    "ax[2].set_xticklabels(('Null', 'No Bias', 'Beta Mean', 'Beta Mode', 'Beta Median', 'Null', 'No Bias'))\n",
    "ax[2].set_ylabel('BIC difference vs. winning model')\n",
    "ax[2].set_title('Model comparison for Patients')\n",
    "ax[2].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T13:37:43.238438Z",
     "start_time": "2018-06-12T13:37:43.233840Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T22:35:38.030604Z",
     "start_time": "2018-06-15T22:35:38.024132Z"
    }
   },
   "source": [
    "***EXERCISE 10***\n",
    "\n",
    "Since this is a synthetic dataset, we can look at our recovery of parameters.\n",
    "\n",
    "The true prior mean, and temperature parameter for each subject is in the dataFrame column 8 and 9 respectively.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Plot the estimated mean of the prior vs. the true mean of the prior he true prior mean.\n",
    "* Plot the estimated temperature parameter against its true value\n",
    "    * Does the recovery of parameters look acceptable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9265470949947079689() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9265470949947079689()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T23:36:30.812109Z",
     "start_time": "2018-06-15T23:36:29.505895Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
    "\n",
    "#Select data 1 subject at a time\n",
    "for i_subj in range(len(df['subject_id'].unique())):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i_subj+1)]\n",
    "    np_subj = np.array(df_subj)\n",
    "    if i_subj < 50:\n",
    "        ax[0].plot((np_subj[0,6]/(np_subj[0,6]+np_subj[0,7])),(est_a[i_subj]/(est_a[i_subj]+est_b[i_subj])),'or',alpha=0.4)\n",
    "        ax[1].plot(np_subj[0,9],est_tau[i_subj],'or',alpha=0.4)\n",
    "    else:\n",
    "        ax[0].plot((np_subj[0,6]/(np_subj[0,6]+np_subj[0,7])),(est_a[i_subj]/(est_a[i_subj]+est_b[i_subj])),'ob',alpha=0.4)\n",
    "        ax[1].plot(np_subj[0,9],est_tau[i_subj],'ob',alpha=0.4)\n",
    "\n",
    "ax[0].set_ylim([-0.05,1.05])\n",
    "ax[0].set_xlim([-0.05,1.05])\n",
    "ax[1].set_ylim([-0.05,1.05])\n",
    "ax[1].set_xlim([-0.05,1.05])\n",
    "ax[0].plot(np.arange(0.1,0.95,0.1), 1*np.arange(0.1,0.95,0.1),'--k',lw=2,label='Ideal recovery X=Y')\n",
    "ax[0].set_ylabel('Estimated mean of prior');\n",
    "ax[0].set_xlabel('True mean of prior');\n",
    "ax[1].plot(np.arange(0.1,0.95,0.1), 1*np.arange(0.1,0.95,0.1),'--k',lw=2,label='Ideal recovery X=Y')\n",
    "ax[1].set_ylabel('Estimated Temperature');\n",
    "ax[1].set_xlabel('True Temperature');\n",
    "ax[0].legend(loc='best', frameon=False)\n",
    "ax[1].legend(loc='best', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex10.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
