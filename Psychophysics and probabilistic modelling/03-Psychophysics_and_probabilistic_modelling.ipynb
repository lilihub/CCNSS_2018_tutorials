{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCNSS 2018 module 2\n",
    "# Tutorial 3 - Psychophysics and probabilistic modelling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please execute the cell below to initialize the notebook environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:02.046514Z",
     "start_time": "2018-06-19T11:27:58.290321Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import  pandas  as  pd             # import pandas\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "import time                        # import time function to time minimize\n",
    "from scipy.optimize import minimize #import optimization functions\n",
    "from scipy.stats import beta       # import beta distribution for BetaBinomial model\n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows to call the function 'hide_toggle' that shows/hides solutions for each exercise\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Show/hide Solution below'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' '\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this notebook we'll clean-up data from a 2-Alternatic Forced Choice task and plot psychometric functions. \n",
    "\n",
    "We will also analyse behavioural data from a task that measure participant innate prior, and implement a conjugate Beta-Bernoulli model that performs the task optimally (ideal-observer) and can recover the participants priors from their behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T13:32:16.839937Z",
     "start_time": "2018-06-08T13:32:16.833357Z"
    }
   },
   "source": [
    "## Background\n",
    "\n",
    "Psychophysics quantitatively investigates the relationship between physical stimuli and the sensations and perceptions they produce. It is a general class of methods that can be applied to study a perceptual system. Modern applications rely heavily on threshold measurement, ideal observer analysis, and signal detection theory.\n",
    "\n",
    "In psychophysics, experiments seek to determine whether the subject can detect a stimulus, identify it, differentiate between it and another stimulus, or describe the magnitude or nature of this difference.\n",
    "\n",
    "A psychometric function is an inferential model applied in detection and discrimination tasks. It models the relationship between a given feature of a physical stimulus, (e.g. velocity, duration, brightness, weight etc.), and forced-choice responses of a human test subject. The psychometric function therefore is a specific application of the generalized linear model (GLM) to psychophysical data. The probability of response is related to a linear combination of predictors by means of a sigmoid link function (e.g. probit, logit, etc.).\n",
    "\n",
    "We analyze data from a two-alternative forced choice task (e.g. the random-dot-task). In these tasks ambiguous evidence for two alternative choices is presented to an observer. The ambiguity results in imperfect performance, that varies with the strength of the ambiguity. This relationship is quantified by the \"psychometric function\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 1 : Data wrangling/munging with Pandas***\n",
    "\n",
    "Loading the data\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Read the data from file 'dots_psychophysics.txt'\n",
    "* Each line is one trial, the columnns encode\n",
    "    - coherence of random dot pattern\n",
    "    - direction of random dot pattern\n",
    "    - the direction the monkey chose\n",
    "    - if the monkey was rewarded\n",
    "    - the monkey's reaction time\n",
    "* direction / choice is encoded as: 1 = 0% coherence, 2 = left stimuli, 3 = right stimuli\n",
    "* on 0% coherence trials the monkey was rewarded randomly\n",
    "* replace numbers '2' and '3' by 'left' and 'right' respectively, and rewarded '1' and '0' into booleans (hint: look up the function 'replace()' in pandas)\n",
    "* print the first 5 rows of the data (hint: look up function 'head()' in pandas )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_15941009177880670180() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_15941009177880670180()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:02.486262Z",
     "start_time": "2018-06-19T11:28:02.068303Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "dotsData = pd.read_csv('data/dots_psychophysics.txt', \n",
    "                       delimiter=' ', skipinitialspace=True, index_col=None, header=None, \n",
    "                       names=['coherence', 'direction', 'choice', 'rewarded', 'rt'])\n",
    "\n",
    "dotsData.replace({'direction': {1.: '0%', 2.: 'left', 3.: 'right'},\n",
    "                  'choice': {1.: '0%', 2.: 'left', 3.: 'right'},\n",
    "                 }, inplace=True)\n",
    "\n",
    "dotsData['rewarded'] = dotsData['rewarded'].astype(np.bool)\n",
    "\n",
    "dotsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T13:47:43.546004Z",
     "start_time": "2018-06-08T13:47:43.540408Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 2: Data manipulation with Pandas***\n",
    "\n",
    "Checking the data\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Check that whenever coherence is 0, direction also encodes the 0% stimulus, and print 'True' or 'False'\n",
    "* Plot the distribution of choices when coherence == 0\n",
    "* Check that for non-zero-coherence trials, whenever the direction == choice then rewarded == True. Print 'True' or 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12878615292263412052() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12878615292263412052()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:05.283262Z",
     "start_time": "2018-06-19T11:28:04.999171Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "check1 = dotsData[dotsData['coherence'] == 0.] \\\n",
    "        ['direction'] \\\n",
    "        .unique() \\\n",
    "        == '0%'\n",
    "        \n",
    "coherentTrials = dotsData[dotsData['coherence'] != 0.] \n",
    "check2 = coherentTrials[coherentTrials['direction'] == coherentTrials['choice']] \\\n",
    "        ['rewarded'] \\\n",
    "        .unique()\n",
    "\n",
    "print('- Check 1 (coherence 0 -> 0% stim): ' + str(check1))\n",
    "print('- Check 2 (direction == choice -> rewarded?): ' + str(check1))\n",
    "\n",
    "nChoicesAt0Coherence = dotsData[dotsData['coherence'] == 0.] \\\n",
    "                                .groupby('choice') \\\n",
    "                                .count() \\\n",
    "                                ['coherence'] # all columns contain the same information\n",
    "\n",
    "# normalize to proportions\n",
    "fracChoisesAt0Coherence = nChoicesAt0Coherence / nChoicesAt0Coherence.sum()\n",
    "fracChoisesAt0Coherence.plot(kind='bar')\n",
    "plt.ylabel('fraction of trials chosen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 3 : Data Wrangling and manipulation in Pandas***\n",
    "\n",
    "Checking the data\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Using a bar plot, plot of the number of trials, broken down by stimulus direction and coherence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_14811099909424287453() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_14811099909424287453()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:08.771584Z",
     "start_time": "2018-06-19T11:28:08.257961Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solutions\n",
    "\n",
    "for direction, directionData in dotsData.groupby('direction'):\n",
    "    plt.figure()\n",
    "    plt.title('Number of available trials for direction == %s' % direction)\n",
    "    directionData.groupby('coherence')['coherence'] \\\n",
    "                    .count() \\\n",
    "                    .plot(kind='bar')\n",
    "    plt.ylabel('number of trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:15:30.716893Z",
     "start_time": "2018-06-08T14:15:30.709225Z"
    }
   },
   "source": [
    "***EXERCISE 4: Psychometric function***\n",
    "\n",
    "A psychometric function is an inferential model applied in detection and discrimination tasks. It models the relationship between a given feature of a physical stimulus, (e.g. velocity, duration, brightness, weight etc.), and forced-choice responses of a human test subject. The psychometric function therefore is a specific application of the generalized linear model (GLM) to psychophysical data. The probability of response is related to a linear combination of predictors by means of a sigmoid link function (e.g. probit, logit, etc.).\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Remove aborted trials, i.e. trials in which the monkey chose the stimulus direction but wasn't rewarded\n",
    "* Plot the psychometric function, i.e. fraction of correct choices vs. coherence  (i.e. plot fraction of right choices for all coherence levels, where for left choices coherence is set to negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3814382185827984158() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3814382185827984158()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:12.281988Z",
     "start_time": "2018-06-19T11:28:12.078442Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "cond_aborted = (dotsData['coherence'] > 0) & \\\n",
    "         (dotsData['direction'] == dotsData['choice']) & \\\n",
    "         (dotsData['rewarded'] == False)\n",
    "dotsData = dotsData[~cond_aborted]\n",
    "\n",
    "zeroPsychometricFunction = pd.Series((dotsData[dotsData['direction'] == '0%']['choice'] == 'right').mean(), index=[0.])\n",
    "    \n",
    "rightPsychometricFunction = dotsData[dotsData['direction'] == 'right'] \\\n",
    "                            .groupby('coherence') \\\n",
    "                            .apply(lambda df: (df['choice'] == 'right').mean())\n",
    "        \n",
    "leftPsychometricFunction = dotsData[dotsData['direction'] == 'left'] \\\n",
    "                            .groupby('coherence') \\\n",
    "                            .apply(lambda df: (df['choice'] == 'right').mean())\n",
    "# flip sign of coherence (which is the index) for leftPsychometricFunction to combine left and right afterwards\n",
    "leftPsychometricFunction.index *= -1\n",
    "\n",
    "# combine the three psychometric functions in one Series\n",
    "psychometricFunction = pd.concat([leftPsychometricFunction, zeroPsychometricFunction, rightPsychometricFunction]) \\\n",
    "                            .sort_index()\n",
    "\n",
    "psychometricFunction.plot()\n",
    "plt.xlabel('Coherence')\n",
    "plt.ylabel('Fraction of right choices')\n",
    "plt.title('Psychometric function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:21:41.270850Z",
     "start_time": "2018-06-08T14:21:41.266976Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic modelling\n",
    "\n",
    "## Background : Optimism Task\n",
    "\n",
    "Optimists hold positive a priori beliefs about the future. In Bayesian statistical theory, a priori beliefs can be overcome by experience. However, optimistic beliefs can at times appear surprisingly resistant to evidence, suggesting that optimism might also influence how new information is selected and learned. \n",
    "\n",
    "Here, we will model how inate optimistic biases influence behaviour in a Pavlovian conditioning task. That is, how participants prior beliefs about *'How likely is something good to happen'* will change their behaviour in a pavlovian instrumental task. \n",
    "\n",
    "***Task***\n",
    "\n",
    "The experiment contained two types of screens (See figure below): \n",
    "    1 - a series of observation screens which subjects have to passively observe. On each of these screens a fractal stimulus was shown to be associated with a binary reward (the presentation of the fractal was followed after 700 ms by the presentation of a full treasure chest) or not (the fractal led to an empty chest); \n",
    "    2 - Participants were then asked to choose between a fractal stimulus (that was observed a couple of times paired with treasures or not),  and a blue square with known probability of winning. In this decision phase, the subjects were told to maximize reward gains.\n",
    "\n",
    "![](./figures/Optimism_task.png)\n",
    "\n",
    "In the example above, the subject sees the yellow fractal twice. Once associated with a reward (full treasure chest), and once without a reward (empty treasure chest). That is, the expected value of the yellow fractal is 0.5 (i.e.: 1 reward + 0 reward / 2 presentations). The participant then arrives to a decision screen (D1), where he/she needs to make a 2-Alternative Force Choice (2-AFC) between the yellow fractal , or the blue target. \n",
    "\n",
    "The probability of the blue target to result in a reward (expected value), is 0.6, denoted by the number of black dots out of 10 (i.e. 6 black dots out of 10). In this particular example, the participant should choose the blue target if he/she wants to maximize the chance of getting a reward on that trial. This is because the expected value of the yellow fractal is 0.5, while the known expected value of the target is 0.6. This means that the target has a higher probability of leading to a rewards than the fractal.\n",
    "\n",
    "Participants see 60 different fractals, seeing each fractal from 3 and up to 8 times each. Since participants cannot accurately count and remember the number of times each fractal was presented with a reward, they must rely on heuristics and/or an appoximation and/or 'gut-feeling' about the *'goodness of a fractal'* based on previous experience with that fractal. This is where we believe the participants' *'optimism bias'* will come into play and shift their decisions.\n",
    "\n",
    "[Ref] http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 5***\n",
    "\n",
    "Loading the data\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Read the data from file 'Optimism_data.csv' or 'Optimism_data.txt'\n",
    "* Each line is one decision trial, the columnns encode\n",
    "    - Column 1: the subject number\n",
    "    - Column 2: the number of times a fractal was rewarded\n",
    "    - Column 3: the number of times a fractal was presented\n",
    "    - Column 4: (ignore for now) \n",
    "    - Column 5: the target probability of reward\n",
    "    - Column 6: Whether participant chose the fractal (1) or target (2)\n",
    "    - ignore other columns\n",
    "* decision / choice is encoded as: 1 = chooses fractal stimulus, 2 = chooses target stimulus\n",
    "* replace numbers '1' and '2' by 'fractal' and 'target' respectively\n",
    "* print the first 5 rows of the data (hint: look up function 'head()' in pandas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_15431995148485599042() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_15431995148485599042()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:16.488204Z",
     "start_time": "2018-06-19T11:28:16.451564Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "df = pd.read_csv('/Users/vincentvalton/Documents/GitHub/ccnss2018/module2/Psychophysics and probabilistic modelling/data/Optimism_data.csv',delimiter=',')\n",
    "\n",
    "df.replace({'choice': {1.: '1', 2.: '0'},\n",
    "                 }, inplace=True)\n",
    "\n",
    "df['choice'] = df['choice'].astype(np.float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 6***\n",
    "\n",
    "Calculate and plot the probability of accepting 'target' as a function of the difference between the true expected value of the fractal and that of the target.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* For each trial, calculate the difference between the fractals' and the targets' expected reward\n",
    "* Bin the difference values into bins of [fractal-target] with the following range : freq_bins=[-1.01, -0.5, 0, 0.5, 1.01]\n",
    "* Calculate the mean acceptance rate per bin and plot it for subject 24.\n",
    "* Fit a sigmoidal response curve to the participant data and plot it (hint: use the sigmoid function below, you may want to use `scipy.optimize.curve_fit`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9995345542560292632() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9995345542560292632()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert your code here    \n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:28:19.354464Z",
     "start_time": "2018-06-19T11:28:19.350433Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def sigmoid(x, x0, k):\n",
    "    y = 1 / (1 + np.exp(-k*(x-x0)))\n",
    "    return y\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:29:09.102423Z",
     "start_time": "2018-06-19T11:29:08.898315Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "# Create column 'diff_frac2targ' which computes difference in expected value between fractal and target\n",
    "df['diff_frac2targ']=df['bin_coef']-df['target_coef']\n",
    "\n",
    "# Define the bins for plotting psychometric curve\n",
    "freq_bins= np.array([-1.01, -0.5, 0, 0.5, 1.01])\n",
    "\n",
    "#Create 'binned' column and bin each trial as belonging to either bin defined in freq_bins\n",
    "df['binned']= pd.cut(df['diff_frac2targ'], bins=freq_bins)\n",
    "\n",
    "#Select data for subject 1 only\n",
    "df1 = df.loc[(df['subject_id']==24)]\n",
    "\n",
    "#Groupby data for subject 1\n",
    "choice_groupby_binned = df1['choice'].groupby(df1['binned'])\n",
    "df1['choice'].groupby(df1['binned']).describe()\n",
    "\n",
    "#Print p(choose fractal) as function of difference in value between fractal & target\n",
    "plt.figure()\n",
    "my_vals=np.array(choice_groupby_binned.mean())\n",
    "choice_groupby_binned.mean().plot(xticks=range(len(my_vals)))\n",
    "plt.ylabel('Probability of choosing `fractal`')\n",
    "plt.xlabel('Binned: Difference in reward probability (Fractal-Target)')\n",
    "plt.title('Psychometric function, Subject: '+ str(24))\n",
    "\n",
    "#Print sigmoid fit to the data\n",
    "my_vals=np.array(choice_groupby_binned.mean())\n",
    "my_vals=my_vals[~np.isnan(my_vals)]\n",
    "popt, pcov = curve_fit(sigmoid, range(len(my_vals)), my_vals)\n",
    "plt.plot(range(len(my_vals)), my_vals, 'o', label='data')\n",
    "plt.plot(np.linspace(0, len(my_vals)-1, 100),sigmoid(np.linspace(0, len(my_vals)-1, 100), *popt), label='Sigmoidal fit')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:21:32.620102Z",
     "start_time": "2018-06-08T16:21:32.615523Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:24:29.934165Z",
     "start_time": "2018-06-08T16:24:29.927545Z"
    }
   },
   "source": [
    "***(BONUS) EXERCISE 7***\n",
    "\n",
    "Calculate and plot the psychometric function for all subject 1 to 50\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Loop over participants, and process their data sequentially\n",
    "    * Use your previous function which calculates the psychometric curve for a given participant data.\n",
    "    * Plot the participant psychometric curve with an alpha=0.4\n",
    "* Note how subjects can have different psychometric function that are shifted either left or right; What do you think this means? (hint: think of it in terms of a bias -- optimism/pessimism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_17352652197373327117() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_17352652197373327117()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:29:17.962224Z",
     "start_time": "2018-06-19T11:29:17.546505Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('Probability of choosing `fractal`')\n",
    "plt.xlabel('Binned: Difference in reward probability (Fractal-Target)')\n",
    "plt.title('Psychometric function for all subjects')\n",
    "\n",
    "#Select data for subject 1 only\n",
    "for i in range(len(df['subject_id'].unique())):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i+1)]\n",
    "\n",
    "    #Groupby data for subject i\n",
    "    choice_groupby_binned = df_subj['choice'].groupby(df_subj['binned'])\n",
    "    \n",
    "    #Print sigmoid fit to the data\n",
    "    my_vals=np.array(choice_groupby_binned.mean())\n",
    "    my_vals=my_vals[~np.isnan(my_vals)]\n",
    "    \n",
    "    plt.plot(range(len(my_vals)), my_vals, '-b', alpha=0.1, label='data')\n",
    "    plt.xticks(range(len(my_vals)), ['[-1,-0.5]' ,'[-0.5,0]' ,'[0,0.5]' ,'[0.5,1]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:24:52.146545Z",
     "start_time": "2018-06-08T16:24:52.138566Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:47:00.311661Z",
     "start_time": "2018-06-08T16:47:00.303383Z"
    }
   },
   "source": [
    "## Background : Probabilistic model\n",
    "\n",
    "We will now simulate an optimal observer model for this task.\n",
    "\n",
    "To do so we will use a Beta-Binomial model, with a softmax link function to add some noise in the responses. \n",
    "\n",
    "The probability density for a Binomial distribution is defined as:\n",
    "\n",
    "\\begin{align*} Bern\\left(N_i,n_i\\right) = \\binom{N_i}{n_i} \\cdot c_{i}^{n_{i}} (1-c_{i})^{N_{i}-n_{i}}  \\end{align*}\n",
    "\n",
    "where, $n$ is the number of times a fractal was rewarded, and $N$ is the number of times it was presented, $c$ is the probability of being rewarded for that fractal. The maximum likelihood estimates of $c$ can be calculated analytically and correspond to:\n",
    "\n",
    "\\begin{align*} P\\left(c\\mid n_i, N_i\\right) = \\frac{n_i}{N_i}\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "The standard $Beta$ distribution gives the probability density of a value $x$ on the interval (0,1):\n",
    "\n",
    "\\begin{align*} Beta\\left(\\alpha,\\beta\\right) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}} {B(\\alpha,\\beta)}\n",
    "\\end{align*}\n",
    "\n",
    "where , $\\beta$ is the Beta function. As you can see the numerator of the $Beta$ distribution has the same functional form as the Binomial distribution. \n",
    "\n",
    "This is because they come from the same family of probability distributions. This means that the $Beta$ prior is a 'conjugate prior' for the Binomial likelihood. We know the analytical form of the posterior distribution for a BetaBinomial conjugate model, such that the posterior is another Beta distribution. As a result we can simplify our model to taking the expectation (mean) of the posterior (a Beta distribution). That is:\n",
    "\n",
    "\\begin{align*} \\hat{C_i}=\\frac{n_i+\\alpha}{N_i+\\alpha+\\beta}\\end{align*}\n",
    "    \n",
    "The Softmax link function is defined as:\n",
    "    \n",
    "\\begin{align*} P(action=fractal)= \\frac{e^{\\left(\\hat{C_i}/ \\tau\\right)}}{e^{\\left(\\hat{C_i} / \\tau \\right)} + e^{\\left({C_{target}}/ \\tau \\right)}} \\end{align*}\n",
    "\n",
    "where $\\tau$ is a temperature parameter that controls stochasticity (the higher $\\tau$ the more random the behaviour, the lower $\\tau$, the more deterministic the behaviour is).\n",
    "\n",
    "**EXERCISE 8**\n",
    "\n",
    "Implement the Softmax function \n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* Implement the Softmax function described above that takes an array of 2 values $x$ as input, as well as a parameter $\\tau$. (hint: for numerical stability you may want to subtract the maximum of the array $x$ to each item in $x$)\n",
    "* Now test your function using the following values, and plot the probability of chosing option 2 as a function of $\\tau$ on the same graph :\n",
    "    * $x=[0,1],\\tau=0.01$, changing $\\tau$ in steps of 0.01 up to 1.2\n",
    "    * $x=[0.2,0.8],\\tau=0.01$, changing $\\tau$ in steps of 0.01 up to 1.2\n",
    "    * $x=[0.4,0.6],\\tau=0.01$, changing $\\tau$ in steps of 0.01 up to 1.2\n",
    "    * $x=[0.49,0.51],\\tau=0.01$, changing $\\tau$ in steps of 0.01 up to 1.2\n",
    "* See how increasing the temperature leads to more 'random' behaviour (choosing the best option -- option 2), while low temperature leads to a 'greedy-like' behaviour (always choosing the option with the highest value). This is why we say that the temperature parameter $\\tau$ controls the exploration/exploitation trade-off.\n",
    "* (optional) Create an interactive bar plot of the softmax probability for $x=[0.4, 0.6, 0.5]$ and interactive values of $\\tau$. See how $\\tau$ changes increases/decreases the distance between the two options as we decrease/increase $\\tau$ respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12760304883848542330() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12760304883848542330()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "def get_softmax(x,tau):\n",
    "    \"\"\"\n",
    "    Function that implements the softmax link function\n",
    "    ----------\n",
    "    x: array of 2 values \n",
    "        Success rates Ci for each option 1 & 2 (in our case success probability of Fractal vs. Target)\n",
    "    tau: integer > 0 \n",
    "        Temperature parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood: \n",
    "        probability of chosing each value of x respectively, as a function of tau, and values of x\n",
    "    \"\"\"\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T11:29:23.337813Z",
     "start_time": "2018-06-19T11:29:23.114832Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "def get_softmax(x,tau):\n",
    "    \"\"\"\n",
    "    Function that implements the softmax link function\n",
    "    ----------\n",
    "    x: array of 2 values \n",
    "        Success rates Ci for each option 1 & 2 (in our case success probability of Fractal vs. Target)\n",
    "    tau: integer > 0 \n",
    "        Temperature parameter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood: \n",
    "        probability of chosing each value of x respectively, as a function of tau, and values of x\n",
    "    \"\"\"\n",
    "    \n",
    "    return (np.exp( (x - np.max(x)) / tau) / np.sum(np.exp( (x - np.max(x)) / tau), axis=0))\n",
    "\n",
    "plt.figure()\n",
    "tau_sim=np.arange(0.01,1.2,0.01)\n",
    "\n",
    "#print(tau_sim)\n",
    "\n",
    "val01 = list()\n",
    "val28 = list()\n",
    "val46 = list()\n",
    "val55 = list()\n",
    "\n",
    "for i in range(len(tau_sim)):\n",
    "    probs=get_softmax([0,1],tau_sim[i])\n",
    "    val01.append(probs[1])\n",
    "    \n",
    "for i in range(len(tau_sim)):\n",
    "    probs=get_softmax([0.2,0.8],tau_sim[i])\n",
    "    val28.append(probs[1])\n",
    "    \n",
    "for i in range(len(tau_sim)):\n",
    "    probs=get_softmax([0.4,0.6],tau_sim[i])\n",
    "    val46.append(probs[1])\n",
    "\n",
    "for i in range(len(tau_sim)):\n",
    "    probs=get_softmax([0.49,0.51],tau_sim[i])\n",
    "    val55.append(probs[1])\n",
    "\n",
    "plt.plot(tau_sim,val01,label='values=[0,1]', lw=5, alpha=0.6)\n",
    "plt.plot(tau_sim,val28,label='values=[0.2,0.8]', lw=5, alpha=0.6)\n",
    "plt.plot(tau_sim,val46,label='values=[0.4,0.6]', lw=5, alpha=0.6)\n",
    "plt.plot(tau_sim,val55,label='values=[0.5,0.5]', lw=5, alpha=0.6)\n",
    "plt.xlabel('Tau')\n",
    "plt.ylabel('Probability of chosing x[1] vs. x[0]')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2457316741093928430() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2457316741093928430()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional question --- insert your code here\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T13:09:52.374806Z",
     "start_time": "2018-06-19T13:09:52.202908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_hist(tau):\n",
    "    x=[0.4, 0.6, 0.5]\n",
    "    plt.bar(range(3), get_softmax(x,tau))\n",
    "    plt.ylim([0,1])\n",
    "    plt.ylabel(r\"P( choose x_i | values (x1,x2,xN) )\")\n",
    "    plt.xlabel('Action')\n",
    "    plt.xticks(range(3), ('x1', 'x2', 'x3'))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_hist, tau=(0.01,1.5,0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T11:34:36.438740Z",
     "start_time": "2018-06-13T11:34:36.373349Z"
    }
   },
   "source": [
    "***EXERCISE 9***\n",
    "\n",
    "Let's implement the BetaBinomial model and see how the amount of evidence for the Likelihood, or the strength (peakiness) of the prior affects the posterior mean of the BetaBinomial model.\n",
    "\n",
    "In our case, the prior location (mean) defines the participants' optimism/pessimism, and the prior strength (peakiness) defines the 'strength' of that optimism/pessimism bias. \n",
    "\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Implement the `get_mean_BetaBinomial` function described above that takes arguments the following parameters $a$, $b$, $n$, and $N$. Where $a$ and $b$ control the shape parameters of the Beta distribution, and $n$, $N$ controls the number of rewarded presentations and the total number of presentations respectively.\n",
    "* Now test your function using the following values, and use the appended plot funciont to plot the probability distribution of Beta given the parameters $a$ and $b$, as well as the mean of the posterior returned by your function :\n",
    "    * $a=5,b=5$, $n=5$, $N=10$\n",
    "    * $a=5,b=5$, $n=1$, $N=2$. Although the ratio $\\frac{n}{N}$ is the same, see how the number of observation affect the liklihood (try also, $a=1.1,a=1.1$, $n=5$, $N=10$)\n",
    "* Let's explore how having a pessimistic bias (i.e. low Beta prior) affects our estimations\n",
    "    * $a=2,b=5$, $n=5$, $N=10$. \n",
    "    * $a=2,b=5$, $n=1$, $N=2$. \n",
    "* Let's explore how having a strong optimistic bias (i.e. High Beta prior) affects our estimations\n",
    "    * $a=5,b=1.1$, $n=5$, $N=10$. \n",
    "    * $a=5,b=1.1$, $n=1$, $N=2$. \n",
    "* For each type of prior (non-informative, pessimistic, optimistic), plot the distribution of the prior, the likelihood as a vertical line, and the mean of the prior as a dashed vertical line.\n",
    "* See how the relative evidence of the likelihood, and the 'strength' (i.e. peaky-ness) of the prior affects the estimate of the posterior distribution (i.e. the dot-dashed line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16195495213589075486() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16195495213589075486()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "def get_mean_BetaBinomial(a, b, n, N):\n",
    "    \"\"\"\n",
    "    Function that implements the BetaBinomial conjugate model and returns the mean of the posterior\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: integer > 0\n",
    "        Number of presentations for fractal\n",
    "    n: integer > 0 & =< N\n",
    "        Number of rewarded presentations of the fractal\n",
    "    c: float > [0..1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    negative log-likelihood: \n",
    "        probability of occurence given the parameters\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T11:34:44.766906Z",
     "start_time": "2018-06-14T11:34:44.757595Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution for functions\n",
    "\n",
    "def get_mean_BetaBinomial(a, b, n, N):\n",
    "    \"\"\"\n",
    "    Function that implements the BetaBinomial conjugate model and returns the mean of the posterior\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: integer > 0\n",
    "        Number of presentations for fractal\n",
    "    n: integer > 0 & =< N\n",
    "        Number of rewarded presentations of the fractal\n",
    "    c: float > [0..1]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    negative log-likelihood: \n",
    "        probability of occurence given the parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    c = ( n + a ) / (N + a + b)\n",
    "    \n",
    "    return c\n",
    "\n",
    "def plot_prior_likelihood_posterior(a, b, n, N, ax, subplot_ids):\n",
    "    x = np.linspace(0.01,0.99, 100)\n",
    "    ax[subplot_ids[0],subplot_ids[1]].plot(x, beta.pdf(x, a, b), lw=5, alpha=0.6, label='Prior: a='+ str(a)+' ,b='+str(b))\n",
    "    ax[subplot_ids[0],subplot_ids[1]].axvline((n/N), label='Likelihood: n='+str(n)+' ,N='+str(N))\n",
    "    ax[subplot_ids[0],subplot_ids[1]].axvline(get_mean_BetaBinomial(a,b,n,N),linestyle='-.', label='Posterior mean: '+str(round(get_mean_BetaBinomial(a,b,n,N),2)))\n",
    "    ax[subplot_ids[0],subplot_ids[1]].legend(loc='best', frameon=False)\n",
    "   \n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T11:34:49.815678Z",
     "start_time": "2018-06-14T11:34:48.436008Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "fig, ax = plt.subplots(3, 2,figsize=(20,15))\n",
    "\n",
    "plot_prior_likelihood_posterior(1.1,1.1,5,10, ax, [0,0])\n",
    "plot_prior_likelihood_posterior(1.1,1.1,5,10, ax, [0,1])\n",
    "plot_prior_likelihood_posterior(5,5,1,2, ax, [0,1])\n",
    "plot_prior_likelihood_posterior(2,5,1,2, ax, [1,0])\n",
    "plot_prior_likelihood_posterior(2,5,5,10, ax, [1,1])\n",
    "plot_prior_likelihood_posterior(5,1.1,1,2, ax, [2,0])\n",
    "plot_prior_likelihood_posterior(5,1.1,5,10, ax, [2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T12:19:44.150281Z",
     "start_time": "2018-06-13T12:19:44.142144Z"
    }
   },
   "source": [
    "***EXERCISE 10***\n",
    "\n",
    "We will now use our Softmax link function and our BetaBinomial function to estimate the $\\alpha$, $\\beta$, and $\\tau$ parameters for each subject.\n",
    "\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* Complete the function `get_negLL_mean_BetaBinomial(parameters, data)`, where `parameters=[a, b, tau]`\n",
    "* For each subject, use the optimization function `sp.optimize.minimize` to find the MLE parameters for each subject. Use `initial_guess=[1,1,0.1]` and `bounds=[(0.01,6),(0.01,6),(0.01,0.8)]`. (hint: you may want to use a wrapper as used in the model fitting tutorial)\n",
    "* For all subjects plot the correlation between true model parameters $tau$ and the prior mean $\\frac{a}{a+b}$ and estimated model parameters. The true prior mean, and temperature parameter for each subject is in the dataFrame column 8 and 9 respectively. Does the recovery of parameters look acceptable?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_18215009772804450187() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_18215009772804450187()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "def get_negll_mean_BetaBinom(a,b,tau, data):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the BetaBinomial model with softmax link function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 3: 1st entry is a (shape of Beta prior), 2nd is b \n",
    "        (2nd shape parameter of Beta prior), 3rd is tau (temperature parameter)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    data : array_like of decision trials.\n",
    "        contains n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T13:58:57.757605Z",
     "start_time": "2018-06-14T13:58:57.749326Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Solution for functions\n",
    "\n",
    "def get_negll_mean_BetaBinom(a,b,tau, data):\n",
    "    '''\n",
    "    Determines the negative loglikelihood of the BetaBinomial model with softmax link function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter : array_like of float\n",
    "        length 3: 1st entry is a (shape of Beta prior), 2nd is b \n",
    "        (2nd shape parameter of Beta prior), 3rd is tau (temperature parameter)\n",
    "        Note: we pack mu and B in one parameter because we want to\n",
    "        make it compatible for later use with sp.optimize.minimize\n",
    "    data : array_like of decision trials.\n",
    "        contains n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        negative log-likelihood\n",
    "    '''\n",
    "    \n",
    "    l=list()\n",
    "    \n",
    "    for i_trial in range(len(data)):\n",
    "        n=data[i_trial,1]\n",
    "        N=data[i_trial,2]\n",
    "        target=data[i_trial,4]\n",
    "        c_hat= get_mean_BetaBinomial(a, b, n, N)\n",
    "        choice_likelihoods=get_softmax([target,c_hat],tau)+1e-100     #target always 1st elem (0), and fractal 2nd elem (1), so that it matches df['choice']=0 or 1 for target/fractal respectively  \n",
    "        l.append(choice_likelihoods[int(data[i_trial,5])])        \n",
    "        \n",
    "    return -np.sum(np.log(l))\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-14T14:54:54.586872Z",
     "start_time": "2018-06-14T14:54:46.532626Z"
    },
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "get_nll_mean_BetaBinomial_wrapper = lambda parameters, data: get_negll_mean_BetaBinom(parameters[0], parameters[1], parameters[2], data)\n",
    "\n",
    "# Store parameters found\n",
    "est_a, est_b, est_tau = list(), list(), list()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,7))\n",
    "\n",
    "# Optimization (find parameters that minimize nll)\n",
    "initial_guess = [1,1,0.1]\n",
    "bounds = [(0.01,6),(0.01,6),(0.01,0.8)] # Optimization bounds\n",
    "\n",
    "#Select data 1 subject at a time\n",
    "for i_subj in range(len(df['subject_id'].unique())):\n",
    "    \n",
    "    df_subj = df.loc[(df['subject_id']==i_subj+1)]\n",
    "    np_subj = np.array(df_subj)\n",
    "    \n",
    "    t_start_optim = time.time()\n",
    "    res = minimize(get_nll_mean_BetaBinomial_wrapper, \n",
    "               args=(np_subj),\n",
    "               method='SLSQP',x0=initial_guess, bounds=bounds)\n",
    "    t_end_optim = time.time()\n",
    "    est_a.append(res.x[0])\n",
    "    est_b.append(res.x[1])\n",
    "    est_tau.append(res.x[2])\n",
    "    ax[0].plot((np_subj[0,6]/(np_subj[0,6]+np_subj[0,7])),(res.x[0]/(res.x[0]+res.x[1])),'or',alpha=0.6)\n",
    "    ax[1].plot(np_subj[0,9],res.x[2],'or',alpha=0.6)\n",
    "\n",
    "ax[0].set_ylim([-0.05,1.05])\n",
    "ax[0].set_xlim([-0.05,1.05])\n",
    "ax[1].set_ylim([-0.05,1.05])\n",
    "ax[1].set_xlim([-0.05,1.05])\n",
    "ax[0].plot(np.arange(0.1,0.95,0.1), 1*np.arange(0.1,0.95,0.1),'--r',LineWidth=2,label='Ideal recovery X=Y')\n",
    "ax[0].set_ylabel('Estimated mean of prior');\n",
    "ax[0].set_xlabel('True mean of prior');\n",
    "ax[1].plot(np.arange(0.1,0.95,0.1), 1*np.arange(0.1,0.95,0.1),'--r',LineWidth=2,label='Ideal recovery X=Y')\n",
    "ax[1].set_ylabel('Estimated Temperature');\n",
    "ax[1].set_xlabel('True Temperature');\n",
    "ax[0].legend(loc='best', frameon=False)\n",
    "ax[1].legend(loc='best', frameon=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T12:28:51.929556Z",
     "start_time": "2018-06-13T12:28:51.923297Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***EXERCISE 11***\n",
    "\n",
    "We have now shown that we can recover the parameters used to generate the data (suggesting that we should normally be able to model behaviour of participant correctly).\n",
    "\n",
    "As a sanity check however, it is usually good practice to plot the fitted model predictions (also called posterior predictive distribution) against the subjects' behaviour.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "* For subject 24:\n",
    "    * Complete the function `sim_mean_BetaBinomial` described below. (hint: You may want to copy your subject data frame, use your previous function `get_mean_BetaBinomial`, and replace the user choice with the function `numpy.random.choice`)\n",
    "    * Run the model with the estimated subject parameters 1000 times and record choices (hint: you may want to simulate the same dataset with the same parameters 1000 times to plot the mean and standard deviation of the model predictions per bin)\n",
    "    * Calculate the psychometric function from the simulated model parameters and plot them with error bars (hint: You may want to convert your simulated data into a dataFrame)\n",
    "    * Plot the true psychometric function for that participant\n",
    "* Does the model do a good job at recapitulating the data (try for subject 46, and 49)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12741093790422546469() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12741093790422546469()\">Show/hide Solution below </a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here\n",
    "\n",
    "def sim_mean_BetaBinomial(a, b, tau, df_data):\n",
    "    '''\n",
    "   Simulates choices (target=0, fractal=1) given the BetaBinomial model with data as presented to participant \n",
    "   and parameters estimated using MLE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : a (shape of Beta prior),\n",
    "    b : b (shape parameter of Beta prior)\n",
    "    tau: temperature parameter\n",
    "    df_data : dataframe for one subject only, which contains on each line a different trial with:\n",
    "              n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataFrame of containing simulated Choices (ie replace true choices) for the same trace of trials presented to the participant\n",
    "    '''\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T12:54:43.026016Z",
     "start_time": "2018-06-15T12:54:43.019332Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution for function\n",
    "\n",
    "def sim_mean_BetaBinomial(a, b, tau, df_data):\n",
    "    '''\n",
    "   Simulates choices (target=0, fractal=1) given the BetaBinomial model with data as presented to participant \n",
    "   and parameters estimated using MLE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : a (shape of Beta prior),\n",
    "    b : b (shape parameter of Beta prior)\n",
    "    tau: temperature parameter\n",
    "    df_data : dataframe for one subject only, which contains on each line a different trial with:\n",
    "              n, N, target_c, and choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataFrame of containing simulated Choices (ie replace true choices) for the same trace of trials presented to the participant\n",
    "    '''\n",
    "    \n",
    "    np_sim = np.array(df_data)\n",
    "\n",
    "    for i_trial in range(len(np_sim)):\n",
    "        n=np_sim[i_trial,1]\n",
    "        N=np_sim[i_trial,2]\n",
    "        target=np_sim[i_trial,4]\n",
    "        c_hat= get_mean_BetaBinomial(a, b, n, N)\n",
    "        choice_likelihoods=get_softmax([target,c_hat],tau)     #target always 1st elem (0), and fractal 2nd elem (1), so that it matches df['choice']=0 or 1 for target/fractal respectively  \n",
    "        np_sim[i_trial,5]=np.random.choice([0,1], 1, p=choice_likelihoods)        \n",
    "    \n",
    "    df_sim = pd.DataFrame(np_sim)\n",
    "    df_sim[5] = df_sim[5].astype(np.float)\n",
    "    return df_sim\n",
    "\n",
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T13:37:47.580834Z",
     "start_time": "2018-06-15T13:37:38.560614Z"
    }
   },
   "outputs": [],
   "source": [
    "### Solution\n",
    "\n",
    "# Select which participant data to plot & simulate\n",
    "subject_id=24\n",
    "df1 = df.loc[(df['subject_id']==subject_id)]\n",
    "\n",
    "# simulate 1000 repeats of the same trial structure\n",
    "n_repeats=1000\n",
    "p_accept_sim = np.full([n_repeats,len(my_vals)],np.nan)\n",
    "\n",
    "for i_repeats in range(1000):\n",
    "    df_sim1_temp = sim_mean_BetaBinomial(est_a[subject_id-1], est_b[subject_id-1], est_tau[subject_id-1], df1)\n",
    "    choice_groupby_sim_binned = df_sim1_temp[5].groupby(df_sim1_temp[11])\n",
    "    p_accept_sim[i_repeats,:]=np.array(choice_groupby_sim_binned.mean())\n",
    "\n",
    "#Groupby data for subject 'Subject_id'\n",
    "choice_groupby_binned = df1['choice'].groupby(df1['binned'])\n",
    "choice_groupby_binned.describe()\n",
    "\n",
    "#Print p(choose fractal) as function of difference in value between fractal & target\n",
    "plt.figure()\n",
    "choice_groupby_binned.mean().plot(xticks=range(len(my_vals)))\n",
    "plt.ylabel('Probability of choosing `fractal`')\n",
    "plt.xlabel('Binned: Difference in reward probability (Fractal-Target)')\n",
    "plt.title('Psychometric function, Subject: '+ str(subject_id))\n",
    "\n",
    "#Print fit to the data\n",
    "my_vals=np.array(choice_groupby_binned.mean())\n",
    "plt.plot(range(len(my_vals)), my_vals, 'o', label='data')\n",
    "# error bar printing mean simulated choice per bin, error bars represent std of simulated choice proportion\n",
    "plt.errorbar(range(len(my_vals)), np.mean(p_accept_sim,axis=0), yerr=np.std(p_accept_sim,axis=0), label='Model posterior predictive fit')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T13:38:03.037888Z",
     "start_time": "2018-06-15T13:38:03.032729Z"
    }
   },
   "source": [
    "***Expected Output***\n",
    "\n",
    "![](./figures/expected_ex11.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
